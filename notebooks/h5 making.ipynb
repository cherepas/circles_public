{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curname = 'Far'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv with F_N from fixed directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:\\seva\\598_processing' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == '_N_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0], delimiter='\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = np.zeros([4,tempar.shape[0]])\n",
    "tmean[0,:] = np.mean(valar, axis = 0)\n",
    "tmean[1,:] = np.std(valar, axis = 0)\n",
    "tmean[2,:] = np.min(valar, axis = 0)\n",
    "tmean[3,:] = np.max(valar, axis = 0)\n",
    "np.savetxt(r'D:/seva/598test/F_N_1001_stat.csv', tmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[0].split('_Y_N')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "mainpath = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/619csv'\n",
    "cip = []\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == 'Y_N_500.csv':\n",
    "            cip.append(os.path.join(root,filename))\n",
    "landmarks_frame = pd.DataFrame()\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i].split('_Y_N')[0] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(os.path.join(mainpath,'file_pathes.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv with Far from fixed directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:\\seva\\598_processing' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == 'ar_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0], delimiter='\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = np.zeros([4,tempar.shape[0]])\n",
    "tmean[0,:] = np.mean(valar, axis = 0)\n",
    "tmean[1,:] = np.std(valar, axis = 0)\n",
    "tmean[2,:] = np.min(valar, axis = 0)\n",
    "tmean[3,:] = np.max(valar, axis = 0)\n",
    "np.savetxt(r'D:/seva/598test/Far_1001_stat.csv', tmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=valar,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(tempar.shape[0])])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-28:-13] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(r'D:/seva/598test/Far_1001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv for F_N2 only for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "##mainpath = r'D:\\seva\\598_processing\\train' \n",
    "mainpath = r'D:\\seva\\598_processing\\train' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == '_N_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0])\n",
    "tempar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=valar,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(tempar.shape[0])])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-28:-13] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(r'D:/seva/598test/train/F_N_1001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv for F_N2 only for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:\\seva\\598_processing\\val' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == '_N_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0])\n",
    "tempar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=valar,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(tempar.shape[0])])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-28:-13] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(r'D:/seva/598test/val/F_N_1001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv for Far only for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:\\seva\\598_processing\\train' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == 'ar_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0])\n",
    "tempar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=valar,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(tempar.shape[0])])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-28:-13] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(r'D:/seva/598test/train/Far_1001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv for F_N2 only for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:\\seva\\598_processing\\val' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-11:] == 'ar_1001.csv':\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempar = np.genfromtxt(cip[0])\n",
    "tempar.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valar = np.zeros([len(cip),tempar.shape[0]])\n",
    "for i in range(len(cip)):\n",
    "    valar[i,:] = np.genfromtxt(cip[i], delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[i][-28:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=valar,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(tempar.shape[0])])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-28:-13] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(r'D:/seva/598test/val/Far_1001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search of the min max of the sh amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cip = []\n",
    "# mainpath = data_dir \n",
    "# for root, directories, filenames in os.walk(mainpath): \n",
    "#     for filename in filenames:\n",
    "#         if filename[-6:] == 'F_.csv':\n",
    "#             cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.genfromtxt(cip[2], delimiter=',')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxsize = 0\n",
    "# for i in cip:\n",
    "#     if len(np.genfromtxt(i, delimiter=','))>maxsize:\n",
    "#         maxsize = len(np.genfromtxt(i, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F = np.zeros([len(cip),maxsize])\n",
    "# for i in range(len(cip)):\n",
    "#     tempar = np.genfromtxt(cip[i], delimiter=',')\n",
    "#     F[i,:] = np.concatenate((tempar, np.zeros([maxsize-tempar.shape[0]])), axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.savetxt(\"Fparameters.csv\", labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = np.zeros([4,maxsize])\n",
    "tmean[0,:] = np.mean(labels, axis = 0)\n",
    "tmean[1,:] = np.std(labels, axis = 0)\n",
    "tmean[2,:] = np.min(labels, axis = 0)\n",
    "tmean[3,:] = np.max(labels, axis = 0)\n",
    "numpy.savetxt(\"Fparameters-mean.csv\", tmean, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_out = 441\n",
    "# if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh.csv')):\n",
    "\n",
    "landmarks_frame = pd.DataFrame(data=F,index=range(len(cip)),\\\n",
    "                               columns=['f'+str(i) for i in range(maxsize)])\n",
    "landmarks_frame.insert(0, 'file_name', \\\n",
    "                       [cip[i][-22:-7] for i in range(len(cip))])\n",
    "landmarks_frame.to_csv(mainpath+'/Fparameters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #           Minmax3Dimage((0.60117054538415,110.972068294924)),\\\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding max and min of _F_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "#mainpath = r'D:\\seva\\598_processing'\n",
    "#mainpath = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/phenoseed/598/' \n",
    "mainpath = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/phenoseed_csv/598csv/'\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if 'Far_500_prenormalized.csv' in filename:\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = 0\n",
    "mn = 100\n",
    "for i in cip:\n",
    "    tempar = np.genfromtxt(i, delimiter = ',')\n",
    "    if np.max(tempar)>mx:\n",
    "        mx = np.max(tempar)\n",
    "    if np.min(tempar)<mn:\n",
    "        mn = np.min(tempar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn, mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn, mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for min max of ply values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/phenoseed/598/' \n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if 'Surface.ply' in filename:\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minv = np.array([100, 100, 100])\n",
    "maxv = np.array([0, 0, 0])\n",
    "for i in range(len(cip)):\n",
    "    pcd = open3d.io.read_point_cloud(cip[i])\n",
    "    img = np.asarray(pcd.points)\n",
    "    img -= np.mean(img,0)\n",
    "    minc = np.min(img, axis=0)\n",
    "    maxc = np.max(img, axis=0)\n",
    "    for j in range(3):\n",
    "        if minc[j] < minv[j]:\n",
    "            minv[j] = minc[j]\n",
    "        if maxc[j] > maxv[j]:\n",
    "            maxv[j] = maxc[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minv, maxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv - minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minv*0.05, maxv*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minv, maxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(minv > [0, 0, 0]) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor(5/2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = ('/p/home/jusers/cherepashkin1/jureca/'\n",
    "    'cherepashkin1/598test/plot_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all F_N.csv to one file for 598csv9 and 598csv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:/cherepashkin1/phenoseed_csv/598csv9'\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if 'F_N.csv' in filename:\n",
    "            cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ''\n",
    "[os.path.join(j+i) for i in cip[0].split('\\\\')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ''\n",
    "for i in cip[0].split('\\\\')[1:]:\n",
    "    j = os.path.join(j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(cip[0].split('\\\\')[1], cip[0].split('\\\\')[2].replace('_F_N.csv',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip2 = [(i.split('\\\\')[1]+'_'+i.split('\\\\')[2]).replace('_F_N.csv','') for i in cip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = list(set(cip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_N = np.zeros([len(cip),441])\n",
    "for i in range(len(cip)):\n",
    "    F_N[i]=np.genfromtxt(cip[i],delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = [0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "mainpath = r'D:/cherepashkin1/phenoseed_csv/598csv9'\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if 'F_N.csv' in filename:\n",
    "            cip.append(os.path.join(root,filename))\n",
    "cip.sort()\n",
    "F_N = np.zeros([len(cip),441])\n",
    "for i in range(len(cip)):\n",
    "    F_N[i]=np.genfromtxt(cip[i],delimiter=',')\n",
    "df = pd.DataFrame(F_N)\n",
    "df.insert(\n",
    "    0, 'file_name', [i.split('\\\\')[1]+'_'+i.split('\\\\')[2].replace('_F_N.csv','') for i in cip])\n",
    "h5File = \"fromdf.h5\";\n",
    "df.to_hdf(\"D:/cherepashkin1/phenoseed_csv/598csv9_F_N.h5\", \"/data/d1\")\n",
    "df.to_hdf('data.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = os.path.join('a','b')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io import pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_hdf(\"D:/cherepashkin1/phenoseed_csv/598csv9_F_N.h5\", \"/data/d1\")\n",
    "df.to_hdf(\"D:/cherepashkin1/phenoseed_csv/598csv9_F_N.h5\", key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_hdf(\"D:/cherepashkin1/phenoseed_csv/598csv9_F_N.h5\", key='df', mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/cherepashkin1/598test/plot_output/e054/041/pathes_val.txt\", 'r') as f:\n",
    "    pathes = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n',\n",
       " '598csv9/1484719/1492267\\n',\n",
       " '598csv9/1484756/1500240\\n',\n",
       " '598csv9/1484752/1499783\\n',\n",
       " '598csv9/1484743/1495681\\n']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathl = [path.replace('598csv9/','').replace('\\n','').replace('/','_') for path in pathes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.DataFrame()\n",
    "df3 = pd.DataFrame(columns=['file_name'].append([str(i) for i in range(441)]))\n",
    "for path in pathl:\n",
    "    print(path)\n",
    "    print(len(df[df['file_name'].str.contains(path)]))\n",
    "    print(df[df['file_name'].str.contains(path)])\n",
    "#     print(df['file_name'].str.match(path))\n",
    "#     df3 = df[df['file_name'].str.match(path)]\n",
    "    df3.append(df[df['file_name'].str.contains(path)])\n",
    "#     print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.DataFrame()\n",
    "#df3 = pd.DataFrame(columns=['file_name'].append([str(i) for i in range(441)]))\n",
    "st = time.time()\n",
    "fnl = []\n",
    "#fnn = np.zeros([4,441])\n",
    "for i, path in enumerate(pathl):\n",
    "#     print(path)\n",
    "#     print(len(df[df['file_name'].str.contains(path)]))\n",
    "    fnl.append(df[df['file_name'].str.contains(path)].iloc[:, 1:].values.tolist()[0])\n",
    "ft = time.time()\n",
    "print(ft-st)\n",
    "#    fnn[i,:] = df[df['file_name'].str.contains(path)].iloc[:, 1:].to_numpy()\n",
    "#    fnt[i,:] = torch.tensor(df[df['file_name'].str.contains(path)].iloc[:, 1:].values)\n",
    "#     print(df['file_name'].str.match(path))\n",
    "#     df3 = df[df['file_name'].str.match(path)]\n",
    "#     df3.append(df[df['file_name'].str.contains(path)])\n",
    "#     print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.DataFrame()\n",
    "# df3 = pd.DataFrame(columns=['file_name'].append([str(i) for i in range(441)]))\n",
    "# fnl = []\n",
    "st = time.time()\n",
    "fnn = np.zeros([len(pathl),441])\n",
    "for i, path in enumerate(pathl):\n",
    "#     print(path)\n",
    "#     print(len(df[df['file_name'].str.contains(path)]))\n",
    "#     fnl.append(df[df['file_name'].str.contains(path)].iloc[:, 1:].values.tolist()[0])\n",
    "    fnn[i,:] = df[df['file_name'].str.contains(path)].iloc[:, 1:].to_numpy()\n",
    "ft = time.time()\n",
    "print(ft-st)\n",
    "#     fnt[i,:] = torch.tensor(df[df['file_name'].str.contains(path)].iloc[:, 1:].values)\n",
    "#     print(df['file_name'].str.match(path))\n",
    "#     df3 = df[df['file_name'].str.match(path)]\n",
    "#     df3.append(df[df['file_name'].str.contains(path)])\n",
    "#     print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pd.DataFrame()\n",
    "# df3 = pd.DataFrame(columns=['file_name'].append([str(i) for i in range(441)]))\n",
    "# fnl = []\n",
    "# fnn = np.zeros([4,441])\n",
    "st = time.time()\n",
    "fnt = torch.zeros(len(pathl),441)\n",
    "for i, path in enumerate(pathl):\n",
    "#     print(path)\n",
    "#     print(len(df[df['file_name'].str.contains(path)]))\n",
    "#     fnl.append(df[df['file_name'].str.contains(path)].iloc[:, 1:].values.tolist()[0])\n",
    "#     fnn[i,:] = df[df['file_name'].str.contains(path)].iloc[:, 1:].to_numpy()\n",
    "    fnt[i,:] = torch.tensor(df[df['file_name'].str.contains(path)].iloc[:, 1:].values)\n",
    "ft = time.time()\n",
    "print(ft-st)\n",
    "#     print(df['file_name'].str.match(path))\n",
    "#     df3 = df[df['file_name'].str.match(path)]\n",
    "#     df3.append(df[df['file_name'].str.contains(path)])\n",
    "#     print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowl = [i for i in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "F_Nl = F_N[rowl,:]\n",
    "ft = time.time()\n",
    "print(ft-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Nl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_train = np.genfromtxt(\"D:/cherepashkin1/598test/plot_output/e054/047/o_train_139\", delimiter= ',')\n",
    "o_val = np.genfromtxt(\"D:/cherepashkin1/598test/plot_output/e054/047/o_val_138\", delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(441, 'F_N', F_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in ['9', '11']:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "##mainpath = r'D:\\seva\\598_processing\\train' \n",
    "for j in ['9', '11']:\n",
    "    mainpath = r'D:/cherepashkin1/phenoseed_csv/598csv'+j \n",
    "    for root, directories, filenames in os.walk(mainpath): \n",
    "        for filename in filenames:\n",
    "            if 'F_N.csv' in filename:\n",
    "                cip.append(os.path.join(root,filename))\n",
    "    F_Nar = np.zeros([len(cip),441])\n",
    "    for i in range(len(cip)):\n",
    "    #     print(cip)\n",
    "    #     print(np.genfromtxt(cip[i], delimiter=',').shape)\n",
    "        F_Nar[i,:] = np.genfromtxt(cip[i], delimiter=',')\n",
    "        d1 = np.random.random(size = (1000,20))\n",
    "d2 = np.random.random(size = (1000,200))\n",
    "hf = h5py.File('data.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=d1)\n",
    "    np.savetxt('D:/cherepashkin1/phenoseed_csv/598csv'+j+'_F_N.csv', F_Nar, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cip = []\n",
    "##mainpath = r'D:\\seva\\598_processing\\train' \n",
    "for j in ['9', '11']:\n",
    "# d2 = np.random.random(size = (1000,200))\n",
    "    hf = h5py.File('D:/cherepashkin1/phenoseed_csv/598csv'+j+'_F_N.h5', 'w')\n",
    "    hf.create_dataset('dataset', data=np.genfromtxt('D:/cherepashkin1/phenoseed_csv/598csv'+j+'_F_N.csv', delimiter =','))\n",
    "#     np.savetxt('D:/cherepashkin1/phenoseed_csv/598csv'+j+'_F_N.csv', F_Nar, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.random.random(size = (1000,20))\n",
    "d2 = np.random.random(size = (1000,200))\n",
    "hf = h5py.File('data.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=d1)\n",
    "hf.create_dataset('dataset_2', data=d2)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('d1', d1, delimiter = ',')\n",
    "np.savetxt('d2', d2, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('data.h5', 'w')\n",
    "\n",
    "mainpath = r'D:/cherepashkin1/phenoseed/598'\n",
    "cnt = 0\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "#     print(root)\n",
    "    for filename in filenames:\n",
    "        bigimage = np.zeros([36,1800,1000])\n",
    "        for i in range(36):\n",
    "            if 'rotation'+str(i).zfill(3) in filename:\n",
    "                bigimage[i] = np.asarray(io.imread(os.path.join(root,filename)))\n",
    "        hf.create_dataset('dataset_'+str(cnt), data=bigimage)\n",
    "        cnt+=1\n",
    "hf.close()\n",
    "#                 cip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('data.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=d1)\n",
    "hf.create_dataset('dataset_2', data=d2)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import helpers\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class HDF5Dataset(data.Dataset):\n",
    "    \"\"\"Represents an abstract HDF5 dataset.\n",
    "    \n",
    "    Input params:\n",
    "        file_path: Path to the folder containing the dataset (one or multiple HDF5 files).\n",
    "        recursive: If True, searches for h5 files in subdirectories.\n",
    "        load_data: If True, loads all the data immediately into RAM. Use this if\n",
    "            the dataset is fits into memory. Otherwise, leave this at false and \n",
    "            the data will load lazily.\n",
    "        data_cache_size: Number of HDF5 files that can be cached in the cache (default=3).\n",
    "        transform: PyTorch transform to apply to every data instance (default=None).\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, recursive, load_data, data_cache_size=3, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_info = []\n",
    "        self.data_cache = {}\n",
    "        self.data_cache_size = data_cache_size\n",
    "        self.transform = transform\n",
    "\n",
    "        # Search for all h5 files\n",
    "        p = Path(file_path)\n",
    "        assert(p.is_dir())\n",
    "        if recursive:\n",
    "            files = sorted(p.glob('**/*.h5'))\n",
    "        else:\n",
    "            files = sorted(p.glob('*.h5'))\n",
    "        if len(files) < 1:\n",
    "            raise RuntimeError('No hdf5 datasets found')\n",
    "\n",
    "        for h5dataset_fp in files:\n",
    "            self._add_data_infos(str(h5dataset_fp.resolve()), load_data)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # get data\n",
    "        x = self.get_data(\"data\", index)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        else:\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "        # get label\n",
    "        y = self.get_data(\"label\", index)\n",
    "        y = torch.from_numpy(y)\n",
    "        return (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.get_data_infos('data'))\n",
    "    \n",
    "    def _add_data_infos(self, file_path, load_data):\n",
    "        with h5py.File(file_path) as h5_file:\n",
    "            # Walk through all groups, extracting datasets\n",
    "            for gname, group in h5_file.items():\n",
    "                for dname, ds in group.items():\n",
    "                    # if data is not loaded its cache index is -1\n",
    "                    idx = -1\n",
    "                    if load_data:\n",
    "                        # add data to the data cache\n",
    "                        idx = self._add_to_cache(ds.value, file_path)\n",
    "                    \n",
    "                    # type is derived from the name of the dataset; we expect the dataset\n",
    "                    # name to have a name such as 'data' or 'label' to identify its type\n",
    "                    # we also store the shape of the data in case we need it\n",
    "                    self.data_info.append({'file_path': file_path, 'type': dname, 'shape': ds.value.shape, 'cache_idx': idx})\n",
    "\n",
    "    def _load_data(self, file_path):\n",
    "        \"\"\"Load data to the cache given the file\n",
    "        path and update the cache index in the\n",
    "        data_info structure.\n",
    "        \"\"\"\n",
    "        with h5py.File(file_path) as h5_file:\n",
    "            for gname, group in h5_file.items():\n",
    "                for dname, ds in group.items():\n",
    "                    # add data to the data cache and retrieve\n",
    "                    # the cache index\n",
    "                    idx = self._add_to_cache(ds.value, file_path)\n",
    "\n",
    "                    # find the beginning index of the hdf5 file we are looking for\n",
    "                    file_idx = next(i for i,v in enumerate(self.data_info) if v['file_path'] == file_path)\n",
    "\n",
    "                    # the data info should have the same index since we loaded it in the same way\n",
    "                    self.data_info[file_idx + idx]['cache_idx'] = idx\n",
    "\n",
    "        # remove an element from data cache if size was exceeded\n",
    "        if len(self.data_cache) > self.data_cache_size:\n",
    "            # remove one item from the cache at random\n",
    "            removal_keys = list(self.data_cache)\n",
    "            removal_keys.remove(file_path)\n",
    "            self.data_cache.pop(removal_keys[0])\n",
    "            # remove invalid cache_idx\n",
    "            self.data_info = [{'file_path': di['file_path'], 'type': di['type'], 'shape': di['shape'], 'cache_idx': -1} if di['file_path'] == removal_keys[0] else di for di in self.data_info]\n",
    "\n",
    "    def _add_to_cache(self, data, file_path):\n",
    "        \"\"\"Adds data to the cache and returns its index. There is one cache\n",
    "        list for every file_path, containing all datasets in that file.\n",
    "        \"\"\"\n",
    "        if file_path not in self.data_cache:\n",
    "            self.data_cache[file_path] = [data]\n",
    "        else:\n",
    "            self.data_cache[file_path].append(data)\n",
    "        return len(self.data_cache[file_path]) - 1\n",
    "\n",
    "    def get_data_infos(self, type):\n",
    "        \"\"\"Get data infos belonging to a certain type of data.\n",
    "        \"\"\"\n",
    "        data_info_type = [di for di in self.data_info if di['type'] == type]\n",
    "        return data_info_type\n",
    "\n",
    "    def get_data(self, type, i):\n",
    "        \"\"\"Call this function anytime you want to access a chunk of data from the\n",
    "            dataset. This will make sure that the data is loaded in case it is\n",
    "            not part of the data cache.\n",
    "        \"\"\"\n",
    "        fp = self.get_data_infos(type)[i]['file_path']\n",
    "        if fp not in self.data_cache:\n",
    "            self._load_data(fp)\n",
    "        \n",
    "        # get new cache_idx assigned by _load_data_info\n",
    "        cache_idx = self.get_data_infos(type)[i]['cache_idx']\n",
    "        return self.data_cache[fp][cache_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvname = '598csv11'\n",
    "cip = []\n",
    "mainpath = r'D:/cherepashkin1/phenoseed_csv/'+csvname\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if 'F_N.csv' in filename:\n",
    "            cip.append(os.path.join(root,filename))\n",
    "cip.sort()\n",
    "F_N = np.zeros([len(cip),441])\n",
    "for i in range(len(cip)):\n",
    "    F_N[i]=np.genfromtxt(cip[i],delimiter=',')\n",
    "with h5py.File(\"D:/cherepashkin1/phenoseed_csv/\"+csvname+\"F_N.h5\", 'w') as hf:\n",
    "    hf.create_dataset('dataset', data=F_N)\n",
    "    \n",
    "with open('D:/cherepashkin1/phenoseed_csv/'+csvname+'_F_N_file_names.txt', 'w') as f:\n",
    "    for i in cip:\n",
    "        f.write((i.split('\\\\')[1]+'_'+i.split('\\\\')[2]).replace('_F_N.csv','') + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_N2 = np.array(h5py.File(\"D:/cherepashkin1/phenoseed_csv/\"+csvname+\"F_N.h5\", 'r').get('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5270, 441)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_N2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-c29ec43bf2b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/cherepashkin1/phenoseed_csv/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcsvname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_F_N_file_names.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcip2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in cip2:\n",
    "with open('D:/cherepashkin1/phenoseed_csv/'+csvname+'_F_N_file_names.txt','r') as f:\n",
    "    cip2 = f.readlines()\n",
    "cip2 = [c.replace('\\n','') for c in cip2]\n",
    "\n",
    "#     print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02792525291442871\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "indices = []\n",
    "for path in pathl:\n",
    "    indices.append([i for i, s in enumerate(cip2) if path in s][0])\n",
    "F_Nl = F_N[indices,:]\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = np.max(F_N,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441,)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5270, 441)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.expand_dims(np.max(F_N,0),axis=0),5270,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = np.zeros([2,F_N.shape[0],441])\n",
    "tmean[0,:] = np.repeat(np.expand_dims(np.min(F_N,0),axis=0),F_N.shape[0],axis=0)\n",
    "tmean[1,:] = np.repeat(np.expand_dims(np.max(F_N,0),axis=0),F_N.shape[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean[0,:] = np.repeat(np.expand_dims(np.mean(F_N,0),axis=0),F_N.shape[0],axis=0)\n",
    "tmean[1,:] = np.repeat(np.expand_dims(np.std(F_N,0),axis=0),F_N.shape[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 441) (5270, 441) (5270, 441)\n"
     ]
    }
   ],
   "source": [
    "print(F_N.shape, v0.shape, v1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_N3 = F_N - v0/(v1-v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Nw = (F_N - tmean[0,:])/(tmean[1,:]-tmean[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146e7a4ec70>]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.min(F_Nw,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146e7b02b20>]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.max(F_Nw,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(F_N,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 441)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_Nl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Nc = F_Nl[:,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188,\n",
       " 267,\n",
       " 4677,\n",
       " 4278,\n",
       " 3188]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmeanc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmeanget(F_N,fun):\n",
    "#     tmeanc = np.zeros(F_N.shape)\n",
    "    exec(\"tmeanc = np.repeat(np.expand_dims(np.\"+fun+\"(F_N,0),axis=0),F_N.shape[0],axis=0)\")\n",
    "    return(tmeanc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = 'min'\n",
    "exec('tmeanc = np.repeat(np.expand_dims(np.'+\\\n",
    "    fun+'(F_N,0),axis=0),F_N.shape[0],axis=0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5270, 441)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmeanc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmeanc = tmeanget(F_N,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-d732845c7791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmeanc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tmeanc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/circles/finetune_test/csv/pathes_to_598.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_n = np.genfromtxt('D:/cherepashkin1/phenoseed_csv/Y_N_500.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 441)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_list = [10*i for i in range(36)]\n",
    "nsp = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000 18500\n"
     ]
    }
   ],
   "source": [
    "print(int(angle/10)*nsp,\n",
    "            (int(angle/10) +\n",
    "             1)*nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01695537567138672\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "y_n2 = np.zeros([64,\n",
    "                   500,\n",
    "                   441])\n",
    "for i, angle in enumerate(angles_list):\n",
    "    y_n2[i] = \\\n",
    "        y_n[int(angle/10)*nsp:\n",
    "            (int(angle/10) +\n",
    "             1)*nsp, :]\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['path','path1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = [s]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['path', 'path1'], ['path', 'path1'], ['path', 'path1']]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = [('598csv9/1484720/1492412', '598csv9/1484719/1492243', '598csv9/1484738/1494635', '598csv9/1484755/1500157', '598csv9/1484738/1494634', '598csv9/1484725/1493036', '598csv9/1484736/1494403', '598csv9/1484728/1493383', '598csv9/1484729/1493457', '598csv9/1484718/1492158', '598csv9/1484753/1499921', '598csv9/1484752/1499772', '598csv9/1484720/1492403', '598csv9/1484746/1496681', '598csv9/1484723/1492728'), ('598csv9/1484720/1492412', '598csv9/1484719/1492243', '598csv9/1484738/1494635', '598csv9/1484755/1500157', '598csv9/1484738/1494634', '598csv9/1484725/1493036', '598csv9/1484736/1494403', '598csv9/1484728/1493383', '598csv9/1484729/1493457', '598csv9/1484718/1492158', '598csv9/1484753/1499921', '598csv9/1484752/1499772', '598csv9/1484720/1492403', '598csv9/1484746/1496681', '598csv9/1484723/1492728'), ('598csv9/1484720/1492412', '598csv9/1484719/1492243', '598csv9/1484738/1494635', '598csv9/1484755/1500157', '598csv9/1484738/1494634', '598csv9/1484725/1493036', '598csv9/1484736/1494403', '598csv9/1484728/1493383', '598csv9/1484729/1493457', '598csv9/1484718/1492158', '598csv9/1484753/1499921', '598csv9/1484752/1499772', '598csv9/1484720/1492403', '598csv9/1484746/1496681', '598csv9/1484723/1492728')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathes = [item for sublist in s3 for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathes = [j for j in pathes for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484720/1492412',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484719/1492243',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484738/1494635',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484755/1500157',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484738/1494634',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484725/1493036',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484736/1494403',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484728/1493383',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484729/1493457',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484718/1492158',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484753/1499921',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484752/1499772',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484720/1492403',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484746/1496681',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728',\n",
       " '598csv9/1484723/1492728']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681',\n",
       " '1484719_1492267',\n",
       " '1484756_1500240',\n",
       " '1484752_1499783',\n",
       " '1484743_1495681']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['model'].str.match('Mac')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from functools import wraps\n",
    "\n",
    "def simple_time_tracker(log_fun):\n",
    "    def _simple_time_tracker(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapped_fn(*args, **kwargs):\n",
    "            start_time = time()\n",
    "\n",
    "            try:\n",
    "                result = fn(*args, **kwargs)\n",
    "            finally:\n",
    "                elapsed_time = time() - start_time\n",
    "\n",
    "                # log the result\n",
    "                log_fun({\n",
    "                    'function_name': fn.__name__,\n",
    "                    'total_time': elapsed_time,\n",
    "                })\n",
    "                \n",
    "            return result\n",
    "\n",
    "        return wrapped_fn\n",
    "    return _simple_time_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _log(message):\n",
    "    print('[SimpleTimeTracker] {function_name} {total_time:.3f}'.format(**message))\n",
    "@simple_time_tracker(_log)\n",
    "def fun():\n",
    "    np.sum(np.zeros(1000000)/np.zeros(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
