{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "# In[3]:\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import open3d \n",
    "import torch\n",
    "import horovod.torch as hvd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from skimage import io, transform, data\n",
    "from skimage.measure import regionprops\n",
    "from skimage import filters\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from scipy.special import sph_harm\n",
    "import sys\n",
    "import shutil\n",
    "from numpy import linalg as LA\n",
    "\n",
    "# In[4]:\n",
    "#from cnet import *\n",
    "exec('from experiments.'+str(opt.expnum)+' import cnet')\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# In[5]:\n",
    "if torch.cuda.device_count()>1:\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.cuda.device_count()==1:\n",
    "    device = torch.device('cuda')\n",
    "else: \n",
    "    device = torch.device('cpu')\n",
    "print(device)\n",
    "# In[6]:\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-bs', type=int, default=4)\n",
    "parser.add_argument('-epoch', type=int, default=8)\n",
    "parser.add_argument('-bn', type=int, default=8)\n",
    "parser.add_argument('-lr', type=float, default=5e-5)\n",
    "parser.add_argument('-dataparallel', type=bool, default=True)\n",
    "parser.add_argument('-minmax', dest='minmax', action='store_true')\n",
    "parser.add_argument('-no_minmax', dest='minmax', action='store_false')\n",
    "parser.set_defaults(minmax=False)\n",
    "parser.add_argument('-minmax3dimage', dest='minmax3dimage', action='store_true')\n",
    "parser.add_argument('-no_minmax3dimage', dest='minmax3dimage', action='store_false')\n",
    "parser.set_defaults(minmax3dimage=False)\n",
    "parser.add_argument('-normalize', dest='normalize', action='store_true')\n",
    "parser.add_argument('-no_normalize', dest='normalize', action='store_false')\n",
    "parser.set_defaults(normalize=False)\n",
    "parser.add_argument('-center', dest='center', action='store_true')\n",
    "parser.add_argument('-no_center', dest='center', action='store_false')\n",
    "parser.set_defaults(center=False)\n",
    "parser.add_argument('-downsample', type=int, default=1)\n",
    "parser.add_argument('-classicnorm', dest='classicnorm', action='store_true')\n",
    "parser.add_argument('-no_classicnorm', dest='classicnorm', action='store_false')\n",
    "parser.set_defaults(classicnorm=False)\n",
    "parser.add_argument('-ampl', type=int, default=441)\n",
    "parser.add_argument('-cmscrop', type=int, default=0)\n",
    "parser.add_argument('-rescale', type=int, default=225)\n",
    "parser.add_argument('-use_adasum',type=bool, default = False)\n",
    "parser.add_argument('-gradient_predivide_factor', type=float, default=1.0,\n",
    "                    help='apply gradient predivide factor in optimizer (default: 1.0)')\n",
    "parser.add_argument('-expnum',type=str, default = '111')\n",
    "parser.add_argument('-hidden_dim',type=str, default = 'hidden_dim = np.hstack((np.repeat(128, 3),441))')\n",
    "parser.add_argument('-chidden_dim',type=str, default = 'chidden_dim = np.hstack((96,128,np.repeat(256, 3)))')\n",
    "parser.add_argument('-kernel_sizes',type=str, default = 'kernel_sizes = np.hstack((7,np.repeat(3, 5)))')\n",
    "parser.add_argument('-input3d', dest='inputt', action='store_true')\n",
    "parser.add_argument('-input2d', dest='inputt', action='store_false')\n",
    "parser.set_defaults(inputt=False)\n",
    "#parser.add_argument('-outputt', type=str, default = 'SH')\n",
    "parser.add_argument('-num_input_images', type=int, default=3)\n",
    "parser.add_argument('-model_name', type=str, default='')\n",
    "parser.add_argument('-use_pretrained', dest='use_pretrained', action='store_true')\n",
    "parser.add_argument('-no_use_pretrained', dest='use_pretrained', action='store_false')\n",
    "parser.set_defaults(use_pretrained=False)\n",
    "parser.add_argument('-weight_decay', type=float, default=0)\n",
    "parser.add_argument('-merging_order', type=str, default='')\n",
    "parser.add_argument('-angle_rand', type=str, default='yes')\n",
    "parser.add_argument('-specie', type=str, default='619')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "tstart = time.time()\n",
    "hvd.init()\n",
    "torch.cuda.set_device(hvd.local_rank())\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if opt.classicnorm: \n",
    "    datatype = '1000'\n",
    "else:\n",
    "    datatype = '1001'\n",
    "# In[8]:\n",
    "# Helper Functions - train_model\n",
    "# In[9]:\n",
    "def my_loss(output, target):\n",
    "    l = torch.mean(torch.multiply(weightv,(output - target))**2)\n",
    "    return l\n",
    "# Y_N = np.genfromtxt('1491988Y_N.csv',delimiter=',')\n",
    "# D = np.genfromtxt('1491988bX.csv',delimiter=',')\n",
    "# F = np.matmul(Y_N,coef)\n",
    "# x = np.zeros([3,1000])\n",
    "# x[0,:] = F * np.cos(D[0,:]) * np.sin(D[1,:])\n",
    "# x[1,:] = F * np.sin(D[0,:]) * np.sin(D[1,:])\n",
    "# x[2,:] = F * np.cos(D[1,:])\n",
    "def train_model(model, dataloaders, samplers, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "#    train_sampler.set_epoch(epoch)\n",
    "#    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    lossar = np.zeros([2,num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            rloss = 0.0\n",
    "            train_sampler = samplers[phase]\n",
    "            train_sampler.set_epoch(epoch)            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
    "                if i_batch == bn:\n",
    "                    break\n",
    "                inputs = sample_batched['image']\n",
    "                labels = sample_batched['landmarks']\n",
    "                y_n = sample_batched['y_n']\n",
    "                far = sample_batched['far']\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    if opt.inputt:\n",
    "                        x = inputs\n",
    "                        y = torch.zeros([x.shape[0], x.shape[1]])\n",
    "                        for i in range(x.shape[0]):\n",
    "                            y[i,:] = torch.sqrt(x[i,:,0]*x[i,:,0]+x[i,:,1]*x[i,:,1]+x[i,:,2]*x[i,:,2])\n",
    "                        y = torch.unsqueeze(y,2)\n",
    "                        y = y.cuda()\n",
    "                        outputs = model(y)\n",
    "                    else:\n",
    "                        if not opt.merging_order: \n",
    "                            outputs = model(inputs)\n",
    "                        elif opt.merging_order = 'before_fc':\n",
    "                            outputs = model(inputs)\n",
    "                    #print('y_n.shape,outputs.shape=',y_n.shape,outputs.shape)\n",
    "                    F = torch.zeros(y_n.shape[0],y_n.shape[1]).cuda()\n",
    "                    for i in range(y_n.shape[0]):\n",
    "                        F[i] = torch.matmul(y_n[i],outputs[i])\n",
    "                    loss = torch.sqrt(torch.sum((far-F)**2))\n",
    "                    #loss = criterion(outputs, labels)\n",
    "#                         F = torch.matmul(outputs,Y_N2)\n",
    "                    #loss = my_loss(outputs,labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                rloss += loss.item()\n",
    "#                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            if bn < len(dataloaders[phase].dataset):\n",
    "                ebn = bn\n",
    "            else:\n",
    "                ebn = len(dataloaders[phase].dataset)\n",
    "            if phase == 'train':\n",
    "                lossar[0][epoch] = rloss/ebn\n",
    "            else: \n",
    "                lossar[1][epoch] = rloss/ebn          \n",
    "#            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:.6f}'.format(phase, rloss/ebn))\n",
    "#            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "            val_acc_history = []\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return model, lossar, time_elapsed\n",
    "\n",
    "\n",
    "# # Initialize and Reshape the Networks\n",
    "# In[10]:\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "# Load Data\n",
    "# In[11]:\n",
    "class Seed3D_Dataset(Dataset):\n",
    "    \"\"\"seed point cloud dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "#        self.landmarks_frame = pd.read_csv(os.path.join(root_dir,'F_N_1001.csv'))\n",
    "        self.landmarks_frame = pd.read_csv(os.path.join(root_dir,'F_N_'+ datatype + '.csv'))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sp = opt.specie\n",
    "        rd = self.root_dir.replace('598test','598')\n",
    "        if opt.inputt:\n",
    "            img_name = os.path.join(rd, self.landmarks_frame.iloc[idx, 0]+'_Surface.ply').replace('\\\\','/')\n",
    "            pcd = open3d.io.read_point_cloud(img_name)\n",
    "            img = np.asarray(pcd.points)\n",
    "    #         img = np.genfromtxt(img_name, skip_header = 7, skip_footer = 1)\n",
    "            img = np.concatenate((img, np.zeros([58014-img.shape[0],3])), axis=0)\n",
    "        else:\n",
    "            nim = opt.num_input_images\n",
    "            img = np.zeros([nim,1000,1800,1])\n",
    "            if not opt.angle_rand:\n",
    "                angles_list = np.array([10*int(36*i/nim) for i in range(nim)])\n",
    "            elif opt.angle_rand = 'yes':\n",
    "                angles_list = np.random.choice(np.arange(0,360,10), size=nim, replace=False)\n",
    "            for i in range(nim):\n",
    "                img_name = \\\n",
    "                os.path.join(rd,\\\n",
    "                             self.landmarks_frame.iloc[idx, 0],\\\n",
    "                'rotation_'+str(angles_list[i]).zfill(3)+'.tif').replace('\\\\','/')\n",
    "                img[i] = np.expand_dims(np.asarray(io.imread(img_name)), axis=2)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 441)\n",
    "        y_n = np.genfromtxt(os.path.join(self.root_dir.replace('598test','598csv3'), self.landmarks_frame.iloc[idx, 0]+'_Y_N_500.csv').replace('\\\\','/'),delimiter=',')\n",
    "        far = np.genfromtxt(os.path.join(self.root_dir.replace('598test','598csv3'), self.landmarks_frame.iloc[idx, 0]+'_Far_500.csv').replace('\\\\','/'),delimiter=',')\n",
    "        sample = {'image': img, 'landmarks': landmarks, 'y_n': y_n, 'far': far}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "# In[12]:\n",
    "# In[13]:\n",
    "class AmpCrop(object):\n",
    "    \"\"\"Crop the label, spherical harmonics amplitude.\"\"\"\n",
    "    def __init__(self, ampl):\n",
    "        self.ampl = ampl\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks[:,:self.ampl],\n",
    "                'y_n': y_n[:,:self.ampl],\n",
    "                'far': far}\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, device):\n",
    "#        assert isinstance(device, str)\n",
    "        self.device = device\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "\n",
    "        landmarks = np.squeeze(landmarks)\n",
    "        return {'image': torch.Tensor(image).cuda(),\n",
    "                'landmarks': torch.Tensor(landmarks).cuda(),\n",
    "                'y_n': torch.Tensor(y_n).cuda(),\n",
    "                'far': torch.Tensor(far).cuda()}\n",
    "#         return {'image': torch.Tensor(image).to(self.device),\n",
    "#                 'landmarks': torch.Tensor(landmarks).to(self.device)}\n",
    "class Minmax3Dimage(object):\n",
    "    \"\"\"Normalize 3D input data to be laying in [0,1]\"\"\"\n",
    "    def __init__(self,minmax):\n",
    "        minf = minmax[0]\n",
    "        maxf = minmax[1]\n",
    "        self.minf = minf\n",
    "        self.maxf = maxf\n",
    "#        assert isinstance(device, str)\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        image = (image-self.minf)/(self.maxf-self.minf)\n",
    "        #         for i in range(3):\n",
    "#             image[:,i] = (image[:,i]-np.min(image,axis=0)[i])/\\\n",
    "#             (np.max(image,axis=0)[i]-np.min(image,axis=0)[i])\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks, \n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "\n",
    "class Downsample(object):\n",
    "    \"\"\"Downsample the input ply file.\"\"\"\n",
    "    def __init__(self, ds):\n",
    "        #assert isinstance(output_size, (int, tuple))\n",
    "        self.ds = ds\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        ds_image = image[::self.ds,:]\n",
    "        return {'image': ds_image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Shuffleinput(object):\n",
    "    \"\"\"Shuffle the rows of input ply file.\"\"\"\n",
    "    def __init__(self, shuffle_seed):\n",
    "        #assert isinstance(output_size, (int, tuple))\n",
    "        self.shuffle_seed = shuffle_seed\n",
    "    def __call__(self, sample):\n",
    "        np.random.seed(self.shuffle_seed)\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        np.random.shuffle(image) \n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Minmax(object):\n",
    "    \"\"\"Normalize the input data to lay in [0,1].\"\"\"\n",
    "    def __init__(self, tmean):\n",
    "#        assert isinstance(tmean, numpy.ndarray)\n",
    "        self.tmean = tmean\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "#        print(type(landmarks))\n",
    "#        print(type(self.tmean[3]))\n",
    "#        landmarks = (landmarks - self.tmean[2])/(self.tmean[3]-self.tmean[2])\n",
    "        landmarks = (landmarks - np.min(self.tmean[2]))/(np.max(self.tmean[3])-np.min(self.tmean[2]))\n",
    "        \n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Reshape(object):\n",
    "    \"\"\"Normalize the input data to lay in [0,1].\"\"\"\n",
    "    def __init__(self, input_layer):\n",
    "#        assert isinstance(tmean, numpy.ndarray)\n",
    "        self.input_layer = input_layer\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "#        print(type(landmarks))\n",
    "#        print(type(self.tmean[3]))\n",
    "        padval = self.input_layer**2-image.shape[0]\n",
    "        if padval >= 0:\n",
    "            image = np.pad(image, ((0,padval),(0,0)), mode='constant')\n",
    "        else: \n",
    "            image = image[:self.input_layer**2]\n",
    "        image = np.reshape(image, [3,self.input_layer,self.input_layer])\n",
    "#        landmarks = (landmarks - self.tmean[2])/(self.tmean[3]-self.tmean[2]) \n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize the input data to lay in [0,1].\"\"\"\n",
    "    def __init__(self):\n",
    "#        assert isinstance(tmean, numpy.ndarray)\n",
    "        a = 1\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "#        print(type(landmarks))\n",
    "#        print(type(self.tmean[3]))\n",
    "        X = image[:,0]\n",
    "        Y = image[:,1]\n",
    "        Z = image[:,2]\n",
    "        C = np.zeros([3,3])\n",
    "        C[0,0] = np.matmul(X,X.transpose())\n",
    "        C[0,1] = np.matmul(X,Y.transpose())\n",
    "        C[0,2] = np.matmul(X,Z.transpose())\n",
    "        C[1,0] = C[0,1]\n",
    "        C[1,1] = np.matmul(Y,Y.transpose())\n",
    "        C[1,2] = np.matmul(Y,Z.transpose())\n",
    "        C[2,0] = C[0,2]\n",
    "        C[2,1] = C[1,2]\n",
    "        C[2,2] = np.matmul(Z,Z.transpose())\n",
    "        w,v = LA.eig(C)\n",
    "        image = np.matmul(v.transpose(),image.transpose()).transpose()\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Center(object):\n",
    "    \"\"\"Make the center of masses of point cloud to be in the origin.\"\"\"\n",
    "    def __init__(self):\n",
    "#        assert isinstance(tmean, numpy.ndarray)\n",
    "        a = 1\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        image = image - np.mean(image,axis = 0)\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class CmsCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "\n",
    "        h, w = image[0].shape[0:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        h, w = image[0].shape[0:2]\n",
    "        new_image = np.zeros([3,new_h, new_w])\n",
    "        for i in range(3):\n",
    "            img = np.squeeze(255-image[i])\n",
    "            properties = regionprops((img > filters.threshold_otsu(img)).astype(int), img)\n",
    "            cms = tuple(map(lambda x: int(x), properties[0].centroid))\n",
    "            tempa = (255-img[cms[0]-new_h//2:cms[0]+new_h//2,\\\n",
    "                                  cms[1]-new_w//2:cms[1]+new_w//2]).astype(np.uint8)\n",
    "            padh = (new_h-tempa.shape[0])//2\n",
    "            padw = (new_w-tempa.shape[1])//2\n",
    "            tempb = np.pad(tempa, \\\n",
    "                ((padh, new_h-tempa.shape[0]-padh),(padw,new_w-tempa.shape[1]-padw)),\\\n",
    "                mode='constant', constant_values = 255)\n",
    "            new_image[i] = tempb\n",
    "        return {'image': new_image/255, \n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        if opt.inputt:\n",
    "            img = image\n",
    "        else:\n",
    "            h, w = image[0].shape[0:2]\n",
    "            if h != self.output_size:\n",
    "                if isinstance(self.output_size, int):\n",
    "                    if h > w:\n",
    "                        new_h, new_w = self.output_size * h / w, self.output_size\n",
    "                    else:\n",
    "                        new_h, new_w = self.output_size, self.output_size * w / h\n",
    "                else:\n",
    "                    new_h, new_w = self.output_size\n",
    "                new_h, new_w = int(new_h), int(new_w)\n",
    "                img = np.zeros([opt.num_input_images,new_h, new_w])\n",
    "        #        print(img.shape)\n",
    "                for i in range(opt.num_input_images):\n",
    "                    img[i] = np.squeeze(transform.resize(image[i], (new_h, new_w)))\n",
    "                transforms.ToTensor()\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        return {'image': img, \n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}    \n",
    "class Divide255(object):\n",
    "    \"\"\"Normalize the input data to lay in [0,1].\"\"\"\n",
    "    def __init__(self):\n",
    "        a = 1\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks, y_n, far = sample['image'], sample['landmarks'], sample['y_n'], sample['far']\n",
    "        return {'image': image/255,\n",
    "                'landmarks': landmarks,\n",
    "                'y_n': y_n,\n",
    "                'far': far}\n",
    "# In[14]:\n",
    "def getsize(new_hi,ker,srd): \n",
    "    pad = (0,0)\n",
    "    dil = np.asarray((1,1))\n",
    "    return(tuple((np.squeeze((np.asarray(new_hi)+    2*np.asarray(pad)-dil*[np.asarray(ker)-1]+1)/                             np.asarray(srd))).astype(int)))\n",
    "# In[18]:\n",
    "batch_size = opt.bs\n",
    "#data_dir = 'D:/seva/598test'\n",
    "data_dir = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/598test'\n",
    "#model_name = \"densenet\"\n",
    "#ds = 5\n",
    "tmean = np.genfromtxt('/p/home/jusers/cherepashkin1/jureca/circles/finetune_test/tmean.csv', delimiter = ',')\n",
    "minmax,minmax3dimage,normalize,center=['']*4\n",
    "if opt.minmax:\n",
    "    minmax = 'Minmax(tmean[:,:opt.ampl]), '\n",
    "else: \n",
    "    minmax = ''  \n",
    "if opt.minmax3dimage:\n",
    "    minmax3dimage = 'Minmax3Dimage((0.60117054538415,110.972068294924)), '\n",
    "else: \n",
    "    minmax3dimage = '' \n",
    "if opt.normalize:\n",
    "    normalize = 'Normalize(), '\n",
    "else: \n",
    "    normalize = ''\n",
    "if opt.center:\n",
    "    center = 'Center(), '\n",
    "else: \n",
    "    center = ''\n",
    "if opt.cmscrop:\n",
    "    cmscrop = 'CmsCrop(opt.cmscrop),'\n",
    "else: \n",
    "    cmscrop = ''    \n",
    "exec(\"data_transforms = {\\'train\\': transforms.Compose([\"+\\\n",
    "     minmax+minmax3dimage+normalize+center+cmscrop+\\\n",
    "     \"AmpCrop(opt.ampl),Downsample(opt.downsample),Rescale(opt.rescale),Divide255(),ToTensor(device)]),\\\n",
    "     'val': transforms.Compose([\"+\\\n",
    "     minmax+minmax3dimage+normalize+center+cmscrop+\\\n",
    "     \"AmpCrop(opt.ampl),Downsample(opt.downsample),Rescale(opt.rescale),Divide255(),ToTensor(device)])}\")\n",
    "\n",
    "\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "# #             AmpCrop(ampl),\\\n",
    "# #             Minmax(tmean[:,:ampl]),\\\n",
    "#             Minmax3Dimage((0.60117054538415,110.972068294924)),\\\n",
    "#            Downsample(ds),\\\n",
    "# #            Center(),\\\n",
    "# #           Shuffleinput(0),\\\n",
    "# #             Normalize(),\\\n",
    "# #             Reshape(224),\\\n",
    "#             ToTensor(device)\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "# #             AmpCrop(ampl),\\\n",
    "# #             Minmax(tmean[:,:ampl]),\\\n",
    "#             Minmax3Dimage((0.60117054538415,110.972068294924)),\\\n",
    "#            Downsample(ds),\\\n",
    "# #            Center(),\\\n",
    "# #           Shuffleinput(0),\\\n",
    "# #             Normalize(),\\\n",
    "# #             Reshape(224),\\\n",
    "#             ToTensor(device)\n",
    "#     ]),\n",
    "# }\n",
    "kwargs={}\n",
    "if (kwargs.get('num_workers', 0) > 0 and hasattr(mp, '_supports_context') and\n",
    "            mp._supports_context and 'forkserver' in mp.get_all_start_methods()):\n",
    "        kwargs['multiprocessing_context'] = 'forkserver'\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: Seed3D_Dataset(root_dir=os.path.join(data_dir,x), transform=data_transforms[x]) \n",
    "                  for x in ['train', 'val']}\n",
    "samplers = {x: torch.utils.data.distributed.DistributedSampler(image_datasets[x], num_replicas=hvd.size(), rank=hvd.rank()) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=opt.bs, shuffle=False, sampler=samplers[x], num_workers = 0, pin_memory = False, **kwargs) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataset = Seed3D_Dataset(csv_file=mainpath+'/sh_paramters.csv', root_dir=data_dir, transform=data_transform)\n",
    "# dataloader = DataLoader(dataset, bs,\n",
    "#                         shuffle=False, num_workers=0)\n",
    "# Create the Optimizer\n",
    "# In[19]:\n",
    "# # Gather the parameters to be optimized/updated in this run. If we are\n",
    "# #  finetuning we will be updating all parameters. However, if we are \n",
    "# #  doing feature extract method, we will only update the parameters\n",
    "# #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "# #  is True.\n",
    "# params_to_update = model_ft.parameters()\n",
    "# print(\"Params to learn:\")\n",
    "# if feature_extract:\n",
    "#     params_to_update = []\n",
    "#     for name,param in model_ft.named_parameters():\n",
    "#         if param.requires_grad == True:\n",
    "#             params_to_update.append(param)\n",
    "#             print(\"\\t\",name)\n",
    "# else:\n",
    "#     for name,param in model_ft.named_parameters():\n",
    "#         if param.requires_grad == True:\n",
    "#             print(\"\\t\",name)\n",
    "\n",
    "# # Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "# Run Training and Validation Step\n",
    "# In[20]:\n",
    "# Setup the loss fxn\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "bn = opt.bn\n",
    "num_epochs = opt.epoch\n",
    "# model_name = 'densenet'\n",
    "lossar = np.zeros([2,num_epochs])\n",
    "# Train and evaluate\n",
    "exec(opt.hidden_dim)\n",
    "exec(opt.chidden_dim)\n",
    "exec(opt.kernel_sizes)\n",
    "if bool(opt.model_name): \n",
    "    smodel, input_size = initialize_model(opt.model_name, opt.ampl, feature_extract, use_pretrained=opt.use_pretrained)\n",
    "else:\n",
    "    smodel = CNet(hidden_dim,chidden_dim,kernel_sizes,opt.num_input_images, opt.rescale)\n",
    "#if opt.dataparallel:\n",
    "    #smodel = nn.DataParallel(smodel)\n",
    "lr=opt.lr*hvd.local_size()\n",
    "smodel.cuda()\n",
    "#smodel.to(device)\n",
    "optimizer = torch.optim.Adam(smodel.parameters(), lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=opt.weight_decay,             amsgrad=False)\n",
    "\n",
    "# Horovod: broadcast parameters & optimizer state.\n",
    "hvd.broadcast_parameters(smodel.state_dict(), root_rank=0)\n",
    "hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n",
    "\n",
    "# Horovod: (optional) compression algorithm.\n",
    "compression = hvd.Compression.none\n",
    "#compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n",
    "\n",
    "# Horovod: wrap optimizer with DistributedOptimizer.\n",
    "optimizer = hvd.DistributedOptimizer(optimizer,\n",
    "                                     named_parameters=smodel.named_parameters(),\n",
    "                                     compression=compression,\n",
    "                                     op=hvd.Adasum if opt.use_adasum else hvd.Average,    gradient_predivide_factor=opt.gradient_predivide_factor)\n",
    "\n",
    "model, lossar, time_elapsed = train_model(smodel, dataloaders_dict, samplers, criterion, optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "rank = hvd.rank()\n",
    "\n",
    "if rank == 0:\n",
    "    dir1 = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/598test/plot_output/'+opt.expnum\n",
    "    #dirname = '/p/home/jusers/cherepashkin1/jureca/cherepashkin1/598test/plot_output/'+opt.expnum+'/'+str(int(time.time()))+'/'\n",
    "    if not os.path.exists(dir1):\n",
    "        os.mkdir(dir1)\n",
    "    i=0\n",
    "    while True:\n",
    "        n = str(i)\n",
    "        dirname = dir1+'/'+n.zfill(3)+'/'\n",
    "        if not os.path.exists(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "    np.save(dirname+'lossar.npy',lossar)\n",
    "    # In[25]:\n",
    "    plt.rcParams[\"figure.figsize\"] = (9,5)\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    # ymin, ymax = , 2\n",
    "    # axes.set_ylim([ymin,ymax])\n",
    "    labels_text = ['train', 'val']\n",
    "    for i in range(2):\n",
    "        plt.plot(np.arange(lossar.shape[1]),np.log10(lossar[i,:]),label=labels_text[i],linewidth=3)\n",
    "    axes.set_xticks(np.arange(0, int(num_epochs*1.1)),                          max(int(num_epochs*0.1),1))\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.,            fontsize = 24)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.autoscale(enable=True, axis='both', tight=None)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([2.8,4.2])\n",
    "    # ymin, ymax = 0,2\n",
    "    # axes.set_ylim([ymin,ymax])\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('log10(Loss)', fontsize=24)\n",
    "    plt.locator_params(axis=\"x\", nbins=5)\n",
    "    plt.locator_params(axis=\"y\", nbins=5)\n",
    "    plt.savefig(dirname+'learning_curve.png', bbox_inches='tight')\n",
    "    plt.savefig(dirname+'learning_curve.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # ## Return SH coefficient vector from the trained model\n",
    "    # In[18]:\n",
    "    phase = 'val'\n",
    "    bn = 1\n",
    "#    ampl = 441\n",
    "    dataloaders = dataloaders_dict\n",
    "    for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
    "        if i_batch == bn:\n",
    "            break\n",
    "        inputs = sample_batched['image']\n",
    "        if opt.inputt:\n",
    "            x = inputs\n",
    "            y = torch.zeros([x.shape[0], x.shape[1]])\n",
    "            y = y.cuda()\n",
    "            for i in range(x.shape[0]):\n",
    "                y[i,:] = torch.sqrt(x[i,:,0]*x[i,:,0]+x[i,:,1]*x[i,:,1]+x[i,:,2]*x[i,:,2])\n",
    "            y = torch.unsqueeze(y,2)\n",
    "            o = model(y)\n",
    "        else:\n",
    "            o = model(inputs)\n",
    "        gt = sample_batched['landmarks']\n",
    "\n",
    "\n",
    "\n",
    "    if opt.minmax:\n",
    "        ampl = opt.ampl\n",
    "        output = np.multiply(model(inputs).detach().cpu().numpy(),tmean[3,:ampl]-tmean[2,:ampl])+tmean[2,:ampl]\n",
    "        real_output = np.multiply(gt.detach().cpu().numpy(),tmean[3,:ampl]-tmean[2,:ampl])+tmean[2,:ampl]\n",
    "    else:\n",
    "        output = o.detach().cpu().numpy()\n",
    "        real_output = gt.detach().cpu().numpy()\n",
    "    # In[19]:\n",
    "    # In[ ]:\n",
    "    np.savetxt(dirname+'o', output, delimiter = ',')\n",
    "    np.savetxt(dirname+'gt', real_output, delimiter = ',')\n",
    "    # In[ ]:\n",
    "    plt.rc('text', usetex=True)\n",
    "    # Grids of polar and azimuthal angles\n",
    "    theta = np.linspace(0, np.pi, 100)\n",
    "    phi = np.linspace(0, 2*np.pi, 100)\n",
    "    #r = np.linspace(-1, 1, 100)\n",
    "    # Create a 2-D meshgrid of (theta, phi) angles.\n",
    "    theta, phi = np.meshgrid(theta, phi)\n",
    "    # Calculate the Cartesian coordinates of each point in the mesh.\n",
    "    xyz = np.array([np.sin(theta) * np.sin(phi),\n",
    "                    np.sin(theta) * np.cos(phi),\n",
    "                    np.cos(theta)])\n",
    "\n",
    "    # In[ ]:\n",
    "    #coef = np.random.rand(10,10)\n",
    "    def plot_Y(ax, coef):\n",
    "        \"\"\"Plot the spherical harmonic of degree el and order m on Axes ax.\"\"\"\n",
    "        f = np.zeros([100,100]).astype('complex128')\n",
    "        for l in range(int(np.sqrt(len(coef)))):\n",
    "            for m in range(-l,l+1):\n",
    "                fb = coef[l*(l+1)+m] * sph_harm(abs(m), l, phi, theta)\n",
    "                f += fb\n",
    "        Yx, Yy, Yz = np.abs(f) * xyz\n",
    "        cmap = plt.cm.ScalarMappable(cmap=plt.get_cmap('PRGn'))\n",
    "        cmap.set_clim(-0.5, 0.5)\n",
    "\n",
    "        ax.plot_surface(Yx, Yy, Yz,\n",
    "                        facecolors=cmap.to_rgba(f.real),\n",
    "                        rstride=2, cstride=2)\n",
    "        print(Yz.shape)\n",
    "        # Draw a set of x, y, z axes for reference.\n",
    "        ax_lim = 50\n",
    "        ax.plot([-ax_lim, ax_lim], [0,0], [0,0], c='0.5', lw=1, zorder=10)\n",
    "        ax.plot([0,0], [-ax_lim, ax_lim], [0,0], c='0.5', lw=1, zorder=10)\n",
    "        ax.plot([0,0], [0,0], [-ax_lim, ax_lim], c='0.5', lw=1, zorder=10)\n",
    "        # Set the Axes limits and title, turn off the Axes frame.\n",
    "    #    ax.set_title(r'$Y_{{{},{}}}$'.format(el, m))\n",
    "        ax_lim = 40\n",
    "        ax.set_xlim(-ax_lim, ax_lim)\n",
    "        ax.set_ylim(-ax_lim, ax_lim)\n",
    "        ax.set_zlim(-ax_lim, ax_lim)\n",
    "        ax.axis('on')\n",
    "        return(Yx, Yy, Yz)\n",
    "    fig = plt.figure(figsize=plt.figaspect(1.))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    #l, m = 2, 0\n",
    "    # coef = [116.40520943, -4.51331063,  -1.22070776, 2.53049672, 1.25615844,\\\n",
    "    #    1.59720443,  28.4781262,   -0.33878004,  -4.02484515]\n",
    "    Yx, Yy, Yz = plot_Y(ax, output[0])\n",
    "    #plot_Y(ax,6,3)\n",
    "    #plt.savefig('Y{}_{}.png'.format(l, m))\n",
    "    #plt.show()\n",
    "    plt.savefig(dirname+'surface')\n",
    "\n",
    "    file = open(dirname+\"job-parameters.txt\", \"w\") \n",
    "    parameters_list = 'epoch='+str(opt.epoch)+'\\n'\\\n",
    "                'bn='+str(opt.bn)+'\\n'\\\n",
    "                'bs='+str(opt.bs)+'\\n'\\\n",
    "                'lr='+str(opt.lr)+'\\n'\\\n",
    "                'dataparallel='+str(opt.dataparallel)+'\\n'\\\n",
    "#                 'ampcrop='+str(opt.ampcrop)+'\\n'\\\n",
    "                'minmax='+str(opt.minmax)+'\\n'\\\n",
    "                'minmax3dimage='+str(opt.minmax3dimage)+'\\n'\\\n",
    "                'downsample='+str(opt.downsample)+'\\n'\\\n",
    "                'normalize='+str(opt.normalize)+'\\n'\\\n",
    "                'center='+str(opt.center)+'\\n'\\\n",
    "                'classicnorm='+str(opt.classicnorm)+'\\n'\\\n",
    "                'ampl='+str(opt.ampl)+'\\n'\\\n",
    "                'cmscrop='+str(opt.cmscrop)+'\\n'\\\n",
    "                'rescale='+str(opt.rescale)+'\\n'\\\n",
    "                'use_adasum='+str(opt.adasum)+'\\n'\\\n",
    "                'gradient_predivide_factor='+str(opt.gradient_predivide_factor)+'\\n'\\\n",
    "                'expnum='+str(opt.expnum)+'\\n'\\\n",
    "                'time_elapsed='+str(time_elapsed)+'\\n'\\\n",
    "                'hidden_dim='+opt.hidden_dim+'\\n'\\\n",
    "                'chidden_dim='+opt.chidden_dim+'\\n'\\\n",
    "                'kernel_sizes='+opt.kernel_sizes+'\\n'\\\n",
    "                'was it 3d point cloud on input ? = '+str(opt.inputt)+'\\n'\\\n",
    "                'model_name='+opt.model_name+'\\n'\\\n",
    "                'Was it used pretrained model ? ='+str(opt.use_pretrained)+'\\n'\\\n",
    "                'weight_decay='+str(opt.weight_decay)+'\\n'\\\n",
    "                'num_input_images='+str(opt.num_input_images)+'\\n'\n",
    "                'merging_order='+str(opt.merging_order)+'\\n'\n",
    "                'angle_rand='+str(opt.angle_rand)\n",
    "    file.write(parameters_list) \n",
    "    file.close() \n",
    "    \n",
    "    original_stdout = sys.stdout  \n",
    "    with open(dirname+\"job-parameters.txt\", 'a') as f:\n",
    "        sys.stdout = f # Change the standard output to the file we created.\n",
    "        print(smodel)\n",
    "        sys.stdout = original_stdout # Reset the standard output to its original value\n",
    "    # In[ ]:\n",
    "    shutil.copyfile('/p/home/jusers/cherepashkin1/jureca/circles/finetune_test/experiments/'+str(opt.expnum)+'/cnet.py', dirname+\"cnet.py\")\n",
    "    torch.save(model.state_dict(), dirname+\"model\")\n",
    "    print(time.time()-tstart)\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
