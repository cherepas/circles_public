{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform, data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode\n",
    "from skimage.measure import regionprops\n",
    "from skimage import filters\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import imageio as iio\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray  # only needed for incorrectly saved images\n",
    "from skimage.measure import regionprops\n",
    "from skimage.feature import canny\n",
    "from scipy import ndimage as ndi\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-946-74790ac4e0f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-946-74790ac4e0f8>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(ipynb_files)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mipynb_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mipynb_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-946-74790ac4e0f8>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mipynb_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mipynb_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-946-74790ac4e0f8>\u001b[0m in \u001b[0;36mloc\u001b[1;34m(nb)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cells'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcells\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cell_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "depth = 2**8-1.\n",
    "D_out = 441\n",
    "C_in = 3 #how many views of one seed\n",
    "\n",
    "mpl = [r'D:\\data\\seeds\\598', r'D:\\seva\\598_processing', \\\n",
    "            r'/home/cherepashkin/data/598_processing'] \n",
    "mpl = [s.replace('\\\\','/') for s in mpl] \n",
    "i = 0\n",
    "while not os.path.exists(mpl[i]):\n",
    "    i+=1\n",
    "#    mainpath = r'D:\\seva\\598_processing'.replace('\\\\','/')\n",
    "mainpath = mpl[i] \n",
    "print(mainpath)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.device('cuda:5')\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timelapse printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ntime(s):\n",
    "    m = 60\n",
    "    l = [(s/m**2)%24, (s/m)%m, (s)%m]\n",
    "    return([int(x) for x in l])\n",
    "def coco(tl, ni, pt):\n",
    "    sm = sum(tl)\n",
    "    tt = 10*(pt)\n",
    "    if sm > tt: \n",
    "        l = tuple(ntime(np.mean(tl)*ni-sum(tl)))\n",
    "    else: \n",
    "        return([pt,'',''])\n",
    "    if sm > tt and pt%14 != 13:\n",
    "        return([pt+1,str(\"%02d:%02d:%02d,\" % l),''])\n",
    "    elif sm > tt and pt%14 == 13:\n",
    "        return([pt+1,str(\"%02d:%02d:%02d\" % l),'\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (441) into shape (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-468-2fa54e1395bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tmean.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (441) into shape (2)"
     ]
    }
   ],
   "source": [
    "if not(os.path.isfile('tmean.csv') and os.path.isfile(mainpath+'/sh_paramters.csv')):\n",
    "    cip = []\n",
    "    for root, directories, filenames in os.walk(mainpath): \n",
    "        for filename in filenames:\n",
    "            if filename[-8:] == 'F_20.csv':\n",
    "                cip.append(os.path.join(root,filename))\n",
    "    labels = np.zeros([len(cip),D_out])\n",
    "    for i in range(len(cip)):\n",
    "        labels[i,:] = torch.tensor(np.genfromtxt(cip[i], delimiter='\\n'))\n",
    "    tmean = np.zeros([4,D_out])\n",
    "    tmean[0,:] = np.mean(labels, axis = 0)\n",
    "    tmean[1,:] = np.std(labels, axis = 0)\n",
    "    tmean[2,:] = np.min(labels, axis = 0)\n",
    "    tmean[3,:] = np.max(labels, axis = 0)\n",
    "    numpy.savetxt(\"tmean.csv\", tmean, delimiter=\",\")\n",
    "    landmarks_frame = pd.DataFrame(data=labels,index=range(len(cip)),\\\n",
    "                                   columns=['f'+str(i) for i in range(D_out)])\n",
    "    landmarks_frame.insert(0, 'file_name', \\\n",
    "                           [cip[i][-24:-9] for i in range(len(cip))])\n",
    "    landmarks_frame.to_csv(mainpath+'/sh_paramters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = np.genfromtxt(\"tmean.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = np.zeros([3,1000,1800,1])\n",
    "        for i in range(3):\n",
    "            img_name = os.path.join(self.root_dir,\\\n",
    "            self.landmarks_frame.iloc[idx, 0],\\\n",
    "            'rotation_'+str(120*i).zfill(3)+'.tif').replace('\\\\','/') \n",
    "            \n",
    "#             self.root_dir+'/'+self.landmarks_frame.iloc[idx, 0]+\\\n",
    "#             '/rotation_'+ str(120*i).zfill(3) + '.tif'\n",
    "            img[i] = np.expand_dims(np.asarray(io.imread(img_name)), axis=2)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, D_out)\n",
    "        sample = {'image': img, 'landmarks': landmarks}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class EllipseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, param, dsize, transform=None):\n",
    "        \n",
    "        self.dsize = dsize\n",
    "        self.param = param\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dsize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        torch.manual_seed(idx)\n",
    "        np.random.seed(idx)\n",
    "        img, label = genbatch(self.param)\n",
    "        sample = {'image': img, 'landmarks': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def genbatch(param):\n",
    "    new_h, dm, randin = param[0], ft2k(param[1])[1], param[5]\n",
    "    dsize = tuple(np.hstack((1,np.repeat(new_h,dm))))\n",
    "    data = torch.rand(dsize) if randin else torch.zeros(dsize, dtype=torch.float32)\n",
    "    data = data.to(device)\n",
    "    if not(randin):\n",
    "        data = ellipses(labelget(param),param)\n",
    "    return(data.float(), torch.tensor(labelget(param)).to(device))\n",
    "\n",
    "def labelget(param):\n",
    "    new_h, ft, n, gs, ovl, randin = param\n",
    "    k, dm, rn = ft2k(ft)\n",
    "    if ovl == 1: \n",
    "        label = np.random.rand(k*n).astype('f')\n",
    "    else:\n",
    "        label = np.zeros([k*n]).astype('f')        \n",
    "        for l in range(n):\n",
    "            label[l:l+k-rn] = np.random.rand(k-rn).astype('f')\n",
    "            if rn > 1:\n",
    "                for ax in range(rn):\n",
    "                    m = min(label[l+ax], 1-labels[l+ax])\n",
    "                    label[l+k-rn+ax] = (5/new_h - m) * \\\n",
    "                    np.random.rand(1).astype('f') + m\n",
    "            else:\n",
    "                m = min(np.concatenate(\\\n",
    "                        (label[l:l+k-rn], 1-label[l:l+k-rn]), axis=0))\n",
    "                label[l+k-1] = (5/new_h - m) * np.random.rand(1).astype('f') + m\n",
    "    return(label)\n",
    "\n",
    "def ellipses(x, param):\n",
    "    new_h, ft, n, gs, ovl, randin = param\n",
    "    k, dm, rn = ft2k(ft)\n",
    "    I, R = [torch.zeros([new_h]*dm, dtype=torch.float32,\\\n",
    "                        requires_grad=True)]*2\n",
    "    I, R = I.to(device), R.to(device)\n",
    "    for i in range(int(len(x)/k)): \n",
    "        if dm == 2: \n",
    "            X, Y = figure2D_init(new_h)\n",
    "        if dm == 2 and k == 3:\n",
    "            r = torch.sqrt(((X-x[k*i]*new_h)**2 +\\\n",
    "                            (Y-x[k*i+1]*new_h)**2))/new_h\n",
    "            r = r.to(device)\n",
    "            I = I + smoothborder(r, x[k*i:k*(i+1)])\n",
    "            R = (I>=1) + (I<1)*I # delete overlaption, that maximum intensity is 1, but that is less than one remains the same\n",
    "        elif dm == 2 and k == 4:\n",
    "            r = torch.sqrt(\\\n",
    "                (((X-x[k*i]*new_h)/x[k*i+2])**2 +\\\n",
    "                 ((Y-x[k*i+1]*new_h)/x[k*i+3])**2))/new_h\n",
    "            r = r.to(device)\n",
    "            I = I + smoothborder(r, x[k*i:k*(i+1)], gs)\n",
    "            R = (I>=1) + (I<1)*I # delete overlaption, that maximum intensity is 1, but that is less than one remains the same\n",
    "        if dm == 3:\n",
    "            X, Y, Z = figure3D_init(new_h)\n",
    "        if dm == 3 and k == 4:\n",
    "            r = torch.sqrt((X-x[k*i]*new_h)**2 +\\\n",
    "                           (Y-x[k*i+1]*new_h)**2 +\\\n",
    "                           (Z-x[k*i+2]*new_h)**2)/new_h\n",
    "            R = (r<=x[k*i+3])\n",
    "        elif dm == 3 and k == 6:\n",
    "            r = torch.sqrt(((X-x[k*i+0]*new_h)/x[k*i+3])**2+\\\n",
    "              ((Y-x[k*i+1]*new_h)/x[k*i+4])**2+\\\n",
    "              ((Z-x[k*i+2]*new_h)/x[k*i+5])**2)/new_h\n",
    "            R = (r<=t.sqrt((x[k*i+3])**2+(x[k*i+3])**2+(x[k*i+4])**2)) \n",
    "    return(R)\n",
    "\n",
    "def figure2D_init(new_h):\n",
    "    X, Y = [torch.arange(0, new_h, 1, dtype=torch.float32, requires_grad=True)]*2\n",
    "    X, Y = torch.meshgrid(X, Y)\n",
    "    X, Y = X.to(device), Y.to(device)\n",
    "    return(X, Y)\n",
    "\n",
    "def figure3D_init(new_h):\n",
    "    X, Y, Z = [torch.arange(0, new_h, 1, dtype=torch.float32, requires_grad=True)]*3\n",
    "    X, Y, Z = torch.meshgrid(X, Y, Z)\n",
    "    X, Y, Z = X.to(device), Y.to(device), Z.to(device)\n",
    "    return(X, Y, Z)\n",
    "\n",
    "def smoothborder(r, x):\n",
    "    if len(x) == 4:\n",
    "        r0 = torch.sqrt(x[2]**2+x[3]**2)\n",
    "        r0 = r0.to(device)\n",
    "    elif len(x) == 3:\n",
    "        r0 = x[2]\n",
    "    I = (r <= r0)\n",
    "    a = 1\n",
    "    c = 4\n",
    "    if gs == 1:\n",
    "        I2 = (1+a*np.exp(c))/(1+a*torch.exp(c*r/r0))\n",
    "        I = I + (r > r0) * I2\n",
    "    return(I)\n",
    "\n",
    "def ft2k(ft):\n",
    "    if ft == 'circle':\n",
    "        k, dm, rn = 3, 2, 1\n",
    "    elif ft == 'ellipse': \n",
    "        k, dm, rn = 4, 2, 2\n",
    "    elif ft == 'tilted ellipse': \n",
    "        k, dm, rn = 5, 2, 2\n",
    "    elif ft == 'sphere':\n",
    "        k, dm, rn = 4, 3, 1\n",
    "    elif ft == 'ellipsoid':\n",
    "        k, dm, rn = 6, 3, 3\n",
    "    elif ft == 'tilted ellipsoid':\n",
    "        k, dm, rn = 7, 3, 3\n",
    "    return(k, dm, rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AmpCrop(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, ampl):\n",
    "        self.ampl = ampl\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks[:,:self.ampl]}\n",
    "\n",
    "class Norm(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, tmean):\n",
    "#        assert isinstance(tmean, tuple)\n",
    "        self.tmean = tmean\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        landmarks = (landmarks - self.tmean[0])/self.tmean[1]\n",
    "        \n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks}\n",
    "class Minmax(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, tmean):\n",
    "#        assert isinstance(tmean, numpy.ndarray)\n",
    "        self.tmean = tmean\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "#        print(type(landmarks))\n",
    "#        print(type(self.tmean[3]))\n",
    "        landmarks = (landmarks - self.tmean[2])/(self.tmean[3]-self.tmean[2])\n",
    "        \n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks}\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, device):\n",
    "#        assert isinstance(device, str)\n",
    "        self.device = device\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        landmarks = np.squeeze(landmarks)\n",
    "        return {'image': torch.Tensor(image).to(self.device),\n",
    "                'landmarks': torch.Tensor(landmarks).to(self.device)}\n",
    "class CmsCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image[0].shape[0:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        h, w = image[0].shape[0:2]\n",
    "        new_image = np.zeros([3,new_h, new_w])\n",
    "        for i in range(3):\n",
    "            img = np.squeeze(255-image[i])\n",
    "            properties = regionprops((img > filters.threshold_otsu(img)).astype(int), img)\n",
    "            cms = tuple(map(lambda x: int(x), properties[0].centroid))\n",
    "#            print((cms[0]-new_h//2)-(cms[0]+new_h//2),(cms[1]-new_w//2)-(cms[1]+new_w//2))\n",
    "#            print(new_image.shape)\n",
    "            tempa = (255-img[cms[0]-new_h//2:cms[0]+new_h//2,\\\n",
    "                                  cms[1]-new_w//2:cms[1]+new_w//2]).astype(np.uint8)\n",
    "            padh = (new_h-tempa.shape[0])//2\n",
    "            padw = (new_w-tempa.shape[1])//2\n",
    "            tempb = np.pad(tempa, \\\n",
    "                ((padh, new_h-tempa.shape[0]-padh),(padw,new_w-tempa.shape[1]-padw)),\\\n",
    "                mode='constant', constant_values = 255)\n",
    "#            print(tempb.shape)\n",
    "            new_image[i] = tempb\n",
    "        return {'image': new_image/255, 'landmarks': landmarks}\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image[0].shape[0:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = np.zeros([3,new_h, new_w])\n",
    "        for i in range(3):\n",
    "            img[i] = transform.resize(image[i], (new_h, new_w))\n",
    "        transforms.ToTensor()\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "#        print('.', end='')\n",
    "        return {'image': img, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getsize(new_hi,ker,srd): \n",
    "    pad = (0,0)\n",
    "    dil = np.asarray((1,1))\n",
    "    return(tuple((np.squeeze((np.asarray(new_hi)+\\\n",
    "    2*np.asarray(pad)-dil*[np.asarray(ker)-1]+1)/\\\n",
    "                             np.asarray(srd))).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TNet(nn.Module):\n",
    "    def __init__(self, tup) :\n",
    "        super().__init__()\n",
    "        new_h, ampl, m_kernel, m_stride, C_in, ratio = tup\n",
    "        #     6 new_h, 7 ampl, 8 m_kernel, 9 m_stride, 16 C_in, 17 ratio\n",
    "#         new_h, ratio, m_kernel, m_stride, C_in, ampl = \n",
    "# #        m_stride = m_kernel\n",
    "        self.pool = nn.MaxPool2d(m_kernel,m_stride)\n",
    "        idt = tuple(map(lambda x: x, \\\n",
    "                getsize((new_h, int(new_h*ratio)),m_kernel,m_stride)))\n",
    "        input_dim = idt[0]*idt[1]*C_in\n",
    "#        print(idt)\n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for hdim in hidden_dim:\n",
    "            self.layers.append(nn.Linear(current_dim, hdim))\n",
    "            current_dim = hdim\n",
    "        self.layers.append(nn.Linear(current_dim, ampl))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.layers[:-1]:\n",
    "#            print(x.shape)\n",
    "            x = F.leaky_relu(layer(x))\n",
    "        out = F.softmax(self.layers[-1](x))\n",
    "        return out  \n",
    "nnarchitectures = {'TNet':TNet}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train - Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def rbatch(sb, tups):\n",
    "    bs, new_h, ampl, C_in, ratio, randin = tups\n",
    "    if randin == 0:\n",
    "        return(sb['image'],sb['landmarks'])  \n",
    "    elif randin == 1:\n",
    "        return(torch.rand([bs, C_in, new_h, int(ratio*new_h)]).to(device), sb['landmarks'])\n",
    "    elif randin == 2:\n",
    "        return(sb['image'], torch.rand([bs, ampl]).to(device))\n",
    "    elif randin == 3:\n",
    "        return(torch.rand([bs, C_in, new_h, int(ratio*new_h)]).to(device), \\\n",
    "               torch.rand([bs, ampl]).to(device))    \n",
    "def train(tupa):\n",
    "#     0 epochs, 1 bn, 2 bs, 3 lr, 4 modelname, \\\n",
    "#            5 crop_h, 6 new_h, 7 ampl, 8 m_kernel, 9 m_stride, \\\n",
    "#            10 rep, 11 hidden_dim, 12 optim, 13 testf, 14 valf,\\\n",
    "#     15 dataset, 16 C_in, 17 ratio, 18 ft, 19 n, 20 ovl, 21 gs, 22 randin = tupa\n",
    "    \n",
    "    epochs, bn, bs, lr, modelname, optim, testf, valf, dataset = \\\n",
    "    tuple(tupa[i] for i in list(range(0, 5))+list(range(12,16)))\n",
    "    starta = time.time()\n",
    "    dataloader = DataLoader(dataset, bs,\n",
    "                            shuffle=False, num_workers=0)\n",
    "#     6 new_h, 7 ampl, 8 m_kernel, 9 m_stride, 16 C_in, 17 ratio\n",
    "#     6, 7, 16, 17, 8, 9 \n",
    "#     new_h, ratio, m_kernel, m_stride, C_in, ampl = \n",
    "    model = nnarchitectures[modelname](tuple(tupa[i] \\\n",
    "                        for i in list(range(6, 10))+list(range(16,18))))\n",
    "    model.to(device)\n",
    "    if optim == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), \\\n",
    "                    lr, betas=(0.9, 0.999),\\\n",
    "                    eps=1e-08, weight_decay=0, \\\n",
    "                    amsgrad=False)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    tl, pt = [], 0\n",
    "#    pt = 0\n",
    "#    lossa = np.zeros([2, epochs*(bn-2)])\n",
    "    lossa = np.zeros([2, epochs])\n",
    "#    print(bn-2)\n",
    "    tsize = int(bn*testf)\n",
    "    vsize = int(bn*(1-testf)*valf)\n",
    "    tups = tuple(tupa[i] for i in [2, 6, 7, 16, 17, 22])\n",
    "#    print(tsize,vsize,len(dataset))\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "#        print(tsize)\n",
    "#        print(i_batch < tsize, i_batch,i_batch >= tsize and i_batch < tsize + vsize)\n",
    "        if i_batch < tsize:\n",
    "            [xtest, ytest] = rbatch(sample_batched, tups)\n",
    "        elif i_batch >= tsize and i_batch < tsize + vsize:\n",
    "#            print(i_batch)\n",
    "#            return 1\n",
    "            [xval, yval] = rbatch(sample_batched, tups)  \n",
    "        else:\n",
    "            break \n",
    "    for j in range(epochs):\n",
    "        start = time.time()\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            if i_batch < tsize+vsize:\n",
    "                continue\n",
    "            if i_batch == bn:\n",
    "                break\n",
    "            [xtrain, ytrain] = rbatch(sample_batched, tups) \n",
    "            y_pred = model(xtrain)\n",
    "            loss = criterion(y_pred, ytrain)\n",
    "#            print(i_batch,loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#            i_los = j*(bn-2)+i_batch-2\n",
    "            i_los = j\n",
    "#            print(lossa.shape, i_los)\n",
    "#            print(lossa.shape)\n",
    "            lossa[0][i_los] += loss.item()\n",
    "            lossa[1][i_los] += criterion(model(xval), yval).item()\n",
    "        end = time.time()\n",
    "        tl.append(end-start)\n",
    "        col = coco(tl,epochs,pt)\n",
    "        pt = col[0]\n",
    "        print(col[1], end = col[2])\n",
    "    enda = time.time()\n",
    "    timelapse = enda - starta\n",
    "    print('',end='\\n')\n",
    "    lossa[1] *= (bn-vsize-tsize)/vsize\n",
    "    return(model,lossa,timelapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## runtrain - training with different datasets and random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def runtrain(): \n",
    "    timel, timelapse = [0]*2\n",
    "    lossb = np.zeros([4, 2, gpam()[0]])\n",
    "    #lossb = np.zeros([2, 2, epochs*(bn-2)])\n",
    "    for i, dtp in enumerate(['SH', 'el']):\n",
    "        for randin in range(2):\n",
    "            print(randin, i, randin+i*2, dtp)\n",
    "            _, lossb[randin+i*2,:,:], timelapse = \\\n",
    "            train(gpam()+pam(dtp, randin))\n",
    "            timel += timelapse\n",
    "    return(lossb, timel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpam - general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gpam():\n",
    "    epochs = 50 #how many epochs \n",
    "    bn = 50 #how many batches\n",
    "    bs = 50#how many images in a batch\n",
    "    new_h = 400\n",
    "    lr = 5e-5 #learning rate\n",
    "    modelname = 'TNet'\n",
    "    crop_h = 550\n",
    "    ampl = 3\n",
    "    m_kernel = 2\n",
    "    m_stride = 2\n",
    "    rep = '(np.repeat(1024, 10),512)'\n",
    "    hidar = {rep : (np.repeat(1024, 10),512)}\n",
    "    hidden_dim = np.hstack(hidar[rep])\n",
    "    optim = 'adam'\n",
    "    testf = 0\n",
    "    valf = 1/(4-(testf+1)/(testf-1))\n",
    "\n",
    "# dataset = FaceLandmarksDataset(csv_file=mainpath+'/sh_paramters.csv',\n",
    "#                                            root_dir=mainpath)\n",
    "\n",
    "#    print(testf)\n",
    "    return(epochs, bn, bs, lr, modelname, \\\n",
    "           crop_h, new_h, ampl, m_kernel, m_stride, \\\n",
    "           rep, hidden_dim, optim, testf, valf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pam - SH regression hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pam(dtp, randin):\n",
    "    if dtp == 'SH':\n",
    "        crop_h, new_h, ampl = gpam()[5], gpam()[6], gpam()[7]\n",
    "        composed = transforms.Compose([CmsCrop(crop_h),Rescale(new_h),AmpCrop(ampl),\\\n",
    "                                   Minmax(tmean[:,:ampl]),\\\n",
    "                                    ToTensor(device)])\n",
    "        dataset = FaceLandmarksDataset(csv_file=mainpath+'/sh_paramters.csv',\n",
    "                                                   root_dir=mainpath,\n",
    "                                                   transform=composed)\n",
    "        C_in = 3\n",
    "        ratio = 1.8\n",
    "        ft = None #circle 3, ellipse 4, sphere 4, ellipsoid 6, angled ellipse 5, angled ellipsoid 7 \n",
    "        n = None #number of objects per image \n",
    "        ovl = None\n",
    "        gs = None\n",
    "    elif dtp == 'el':\n",
    "        bn, bs, new_h = gpam()[1], gpam()[2], gpam()[6]\n",
    "        C_in = 1\n",
    "        ratio = 1\n",
    "        ft = 'circle' #circle 3, ellipse 4, sphere 4, ellipsoid 6, angled ellipse 5, angled ellipsoid 7 \n",
    "        n = 1 #number of objects per image \n",
    "        ovl = 0\n",
    "        gs = 1    \n",
    "        dataset = EllipseDataset((new_h, ft, n, gs, ovl, randin), bn*bs)        \n",
    "    return(dataset, C_in, ratio, ft, n, ovl, gs, randin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traplot - Draw a plot of the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def traplot(timel):\n",
    "#     tupa = gpam+pam()\n",
    "#     epochs, bn, bs, lr, modelname, \\\n",
    "#            crop_h, new_h, ampl, m_kernel, m_stride, \\\n",
    "#            rep, hidden_dim, optim, testf, valf = gpam()\n",
    "    tupa = gpam()\n",
    "    #     0 epochs, 1 bn, 2 bs, 3 lr, 4 modelname, \\\n",
    "#            5 crop_h, 6 new_h, 7 ampl, 8 m_kernel, 9 m_stride, \\\n",
    "#            10 rep, 11 hidden_dim, 12 optim, 13 testf, 14 valf,\\\n",
    "#     15 dataset, 16 C_in, 17 ratio, 18 ft, 19 n, 20 ovl, 21 gs, 22 randin = tupa\n",
    "# 0, 1, 2, 3, 6, 10, 12\n",
    "    epochs, bn, bs, lr, new_h, rep, optim = \\\n",
    "    tuple(tupa[i] for i in list(range(0, 4))+[6,10,12])        \n",
    "    plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "    linestyles = ['-', '--', '-.', ':', '-', '--',\\\n",
    "                  '-.', ':', '-', '--', '-.', ':']\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "#    labels_text = [['t', 'v'], ['t rand input', 'v rand input'], \\\n",
    "#                   ['t rand output', 'v rand output'], ['t rand both', 'v rand both'],]\n",
    "    #labels_text = [['t', 'v'], ['$\\widetilde{t}$', '$\\widetilde{v}$']]*2 \n",
    "    labels_text = [['t SH', 'v SH'], \\\n",
    "                   ['$\\widetilde{t}$ SH', '$\\widetilde{v}$ SH'], \n",
    "                  ['t el', 'v el'], \\\n",
    "                   ['$\\widetilde{t}$ el', '$\\widetilde{v}$ el']]\n",
    "#     for i in range(len(labels_text)):\n",
    "#         for j in range(len(labels_text[i])):\n",
    "#             labels_text[i][j] += ' SH' if i < 2 else ' el'\n",
    "    for trt in range(lossb.shape[1]):\n",
    "        for isr in range(lossb.shape[0]):\n",
    "#            cura = np.asarray(lossb[isr,trt])\n",
    "            plt.plot(np.arange(lossb.shape[2]), \\\n",
    "                     lossb[isr,trt], label=labels_text[isr][trt], \\\n",
    "                     color = colors[isr], linestyle=linestyles[trt], \\\n",
    "                     linewidth=3)\n",
    "    axes.set_xticks(np.arange(0, int(lossb[0][0].shape[0]*1.1),\\\n",
    "                              max(int(lossb[0][0].shape[0]*0.1),1)))\n",
    "    #axes.set_yticks(np.arange(ymin, ymax, 1))\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0., \\\n",
    "               fontsize = 24)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.autoscale(enable=True, axis='both', tight=None)\n",
    "#     ymin, ymax = 0, 2\n",
    "#     axes.set_ylim([ymin,ymax])\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('MSE Loss', fontsize=24)\n",
    "    plt.savefig('plot output/'+\\\n",
    "                'size='+str(new_h)+\\\n",
    "                'bn'+str(bn)+\\\n",
    "                'bs'+str(bs)+\\\n",
    "                'epochs'+str(epochs)+\\\n",
    "                'layers'+rep+\\\n",
    "                'lr'+str(lr)+\\\n",
    "                'optimizer'+str(optim)+\\\n",
    "                'etime'+format(timel,\".2f\")+\\\n",
    "                '.png', bbox_inches='tight')\n",
    "    plt.title('Learning curve \\n', fontsize=24)\n",
    "    fig.text(.5, -.1, 't - training, v - validation, '\\\n",
    "    'SH - spherical harmonics, \\n el - synthetic ellipses, '\\\n",
    "                       '$\\widetilde{x}$ - random numbers on input',\\\n",
    "             ha='right',fontsize=24)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
