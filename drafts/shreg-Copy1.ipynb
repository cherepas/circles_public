{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as t\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import imageio as iio\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray  # only needed for incorrectly saved images\n",
    "from skimage.measure import regionprops\n",
    "from skimage.feature import canny\n",
    "from scipy import ndimage as ndi\n",
    "import shutil\n",
    "#from models.res_gru_net import ResidualGRUNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = 1000\n",
    "wt = 1800\n",
    "depth = 2**8-1.\n",
    "nh = 500\n",
    "nw = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters depended on dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src = r'D:\\data\\599'.replace('\\\\', '/')\n",
    "src = r'D:\\seva\\598_processing'.replace('\\\\', '/')\n",
    "ido = '598'\n",
    "idn = ido + 'prc'\n",
    "dst = src.replace(ido,idn)\n",
    "k = 90 #how many csv files in a folder, maximum is 90\n",
    "C_in = 3 #how many views of one seed\n",
    "D_out = 441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if t.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timelapse printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ntime(s):\n",
    "    m = 60\n",
    "    l = [(s/m**2)%24, (s/m)%m, (s)%m]\n",
    "    return([int(x) for x in l])\n",
    "def coco(tl, ni):\n",
    "    #s = sum(tl)\n",
    "    l = tuple(ntime(np.mean(tl)*ni-sum(tl)))\n",
    "    if len(tl)%10 != 9:\n",
    "        print (\"%02d:%02d:%02d,\" % l, end = '')\n",
    "    else:\n",
    "        print (\"%02d:%02d:%02d\" % l, end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:03:20,"
     ]
    }
   ],
   "source": [
    "coco([200], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n"
     ]
    }
   ],
   "source": [
    "print('%02d' % 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 20]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntime(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove background and crop relatively to center of mass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(ci):\n",
    "    image = depth - iio.imread(ci)\n",
    "#     image[image<30] = 0\n",
    "#     image[image>200] = 1\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    fmask = (image > threshold_value)\n",
    "    nimage = fmask*image\n",
    "#     qmask = ndi.binary_fill_holes(canny(timage/depth,sigma=sg)+frame)\n",
    "#     nimage = (1-frame)*qmask*image\n",
    "    properties = regionprops(fmask.astype(int), nimage)\n",
    "    cms = tuple(map(lambda x: int(x), properties[0].centroid))\n",
    "    pimage = (depth - nimage[cms[0]-nh//2:cms[0]+nh//2,cms[1]-nw//2:cms[1]+nw//2]).astype(np.uint8)\n",
    "    #print('.', end = '')\n",
    "    return(pimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/seva/598prc_processing'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ig_f(dir, files):\n",
    "    return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "shutil.copytree(src, dst, ignore=ig_f)\n",
    "#shutil.copytree(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.zeros([ht,wt])\n",
    "frame[ht-1][:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00,00:01:48,00:06:09,00:08:28,00:09:50,00:10:59,00:11:28,00:12:11,00:12:32,\n",
      "00:12:48,00:13:08,00:13:19,00:13:31,00:13:43,00:13:46,00:13:52,00:13:55,00:14:06,00:14:09,\n",
      "00:14:17,00:14:17,00:14:21,00:14:24,00:14:30,00:14:32,00:14:38,00:14:37,00:14:39,00:14:40,\n",
      "00:14:44,00:14:49,00:14:53,00:14:56,00:14:57,00:14:55,00:14:55,00:14:56,00:15:00,00:15:01,\n",
      "00:15:01,00:15:00,00:15:03,00:15:04,00:15:10,00:15:20,00:15:21,00:15:23,00:15:24,00:15:26,\n",
      "00:15:32,00:15:31,00:15:32,00:15:31,00:15:29,00:15:29,00:15:29,00:15:35,00:15:36,00:15:38,\n",
      "00:15:42,00:15:42,00:15:46,00:15:47,00:15:47,00:15:48,00:15:46,00:15:45,00:15:45,00:15:47,\n",
      "00:15:47,00:15:46,00:15:46,00:15:45,00:15:45,00:15:45,00:15:46,00:15:45,00:15:44,00:15:43,\n",
      "00:15:42,00:15:42,00:15:43,00:15:43,00:15:44,00:15:43,00:15:42,00:15:41,00:15:40,00:15:41,\n",
      "00:15:41,00:15:40,00:15:40,00:15:39,00:15:39,00:15:39,00:15:40,00:15:39,00:15:38,00:15:37,\n",
      "00:15:36,00:15:35,00:15:37,00:15:37,00:15:37,00:15:35,00:15:35,00:15:35,00:15:36,00:15:37,\n",
      "00:15:38,00:15:39,00:15:41,00:15:43,00:15:45,00:15:45,00:15:45,00:15:46,00:15:47,00:15:47,\n",
      "00:15:48,00:15:48,00:15:48,00:15:42,00:15:44,00:16:07,00:16:06,00:16:07,00:16:11,00:16:14,\n",
      "00:16:21,00:16:22,00:16:23,00:16:25,00:16:25,00:16:30,00:16:34,00:16:35,00:16:38,00:16:40,\n",
      "00:16:44,00:16:47,00:16:49,00:16:56,00:17:01,00:17:04,00:17:05,00:17:08,00:17:10,00:17:11,\n",
      "00:17:12,00:17:12,00:17:13,00:17:14,00:17:14,00:17:15,00:17:16,00:17:17,00:17:17,00:17:19,\n",
      "00:17:20,00:17:21,00:17:21,00:17:21,00:17:25,00:17:29,00:17:31,00:17:34,00:17:36,00:17:37,\n",
      "00:17:38,00:17:38,00:17:38,00:17:38,00:17:40,00:17:41,00:17:41,00:17:41,00:17:40,00:17:41,\n",
      "00:17:42,00:17:42,00:17:41,00:17:40,00:17:39,00:17:38,00:17:38,00:17:38,00:17:36,00:17:36,\n",
      "00:17:34,00:17:34,00:17:34,00:17:33,00:17:32,00:17:31,00:17:31,00:17:30,00:17:29,00:17:29,\n",
      "00:17:28,00:17:27,00:17:26,00:17:26,00:17:25,00:17:25,00:17:24,00:17:23,00:17:22,00:17:21,\n",
      "00:17:20,00:17:20,00:17:19,00:17:19,00:17:19,00:17:18,00:17:17,00:17:17,00:17:18,00:17:17,\n",
      "00:17:16,00:17:15,00:17:14,00:17:14,00:17:14,00:17:13,00:17:12,00:17:11,00:17:10,00:17:10,\n",
      "00:17:09,00:17:08,00:17:07,00:17:07,00:17:06,00:17:05,00:17:05,00:17:04,00:17:03,00:17:03,\n",
      "00:17:03,00:17:03,00:16:59,00:16:59,00:16:59,00:16:58,00:16:57,00:16:56,00:16:56,00:16:55,\n",
      "00:16:54,00:16:54,00:16:53,00:16:52,00:16:52,00:16:51,00:16:51,00:16:51,00:16:50,00:16:50,\n",
      "00:16:49,00:16:48,00:16:47,00:16:47,00:16:47,00:16:46,00:16:46,00:16:45,00:16:44,00:16:44,\n",
      "00:16:43,00:16:43,00:16:42,00:16:42,00:16:41,00:16:41,00:16:40,00:16:40,00:16:47,00:16:47,\n",
      "00:16:47,00:16:46,00:16:46,00:16:45,00:16:44,00:16:44,00:16:43,00:16:43,00:16:42,00:16:41,\n",
      "00:16:41,00:16:40,00:16:40,00:16:39,00:16:39,00:16:39,00:16:38,00:16:37,00:16:37,00:16:36,\n",
      "00:16:36,00:16:35,00:16:35,00:16:34,00:16:33,00:16:33,00:16:33,00:16:32,00:16:32,00:16:31,\n",
      "00:16:30,00:16:30,00:16:30,00:16:29,00:16:29,00:16:28,00:16:28,00:16:27,00:16:27,00:16:26,\n",
      "00:16:25,00:16:25,00:16:24,00:16:24,00:16:23,00:16:23,00:16:22,00:16:22,00:16:21,00:16:21,\n",
      "00:16:20,00:16:20,00:16:19,00:16:19,00:16:19,00:16:19,00:16:18,00:16:18,00:16:17,00:16:17,\n",
      "00:16:16,00:16:16,00:16:16,00:16:16,00:16:15,00:16:14,00:16:14,00:16:14,00:16:14,00:16:14,\n",
      "00:16:14,00:16:13,00:16:13,00:16:13,00:16:12,00:16:12,00:16:11,00:16:11,00:16:10,00:16:10,\n",
      "00:16:10,00:16:09,00:16:09,00:16:08,00:16:06,00:16:06,00:16:05,00:16:05,00:16:04,00:16:04,\n",
      "00:16:03,00:16:03,00:16:02,00:16:02,00:16:02,00:16:01,00:16:01,00:16:01,00:16:00,00:16:00,\n",
      "00:16:00,00:15:59,00:15:59,00:15:59,00:15:58,00:15:58,00:15:57,00:15:57,00:15:57,00:15:56,\n",
      "00:15:56,00:15:55,00:15:55,00:15:54,00:15:54,00:15:54,00:15:54,00:15:53,00:15:53,00:15:52,\n",
      "00:15:52,00:15:52,00:15:52,00:15:51,00:15:51,00:15:50,00:15:50,00:15:50,00:15:49,00:15:49,\n",
      "00:15:48,00:15:48,00:15:47,00:15:47,00:15:47,00:15:47,00:15:46,00:15:46,00:15:45,00:15:46,\n",
      "00:15:45,00:15:45,00:15:44,00:15:44,00:15:44,00:15:44,00:15:44,00:15:44,00:15:43,00:15:43,\n",
      "00:15:42,00:15:42,00:15:42,00:15:42,00:15:41,00:15:41,00:15:40,00:15:40,00:15:40,00:15:39,\n",
      "00:15:39,00:15:39,00:15:38,00:15:38,00:15:38,00:15:38,00:15:38,00:15:37,00:15:37,00:15:37,\n",
      "00:15:36,00:15:36,00:15:35,00:15:35,00:15:35,00:15:35,00:15:34,00:15:34,00:15:33,00:15:33,\n",
      "00:15:33,00:15:33,00:15:32,00:15:32,00:15:31,00:15:31,00:15:31,00:15:31,00:15:30,00:15:30,\n",
      "00:15:30,00:15:29,00:15:29,00:15:29,00:15:28,00:15:28,00:15:28,00:15:27,00:15:27,00:15:27,\n",
      "00:15:27,"
     ]
    }
   ],
   "source": [
    "ds = []\n",
    "tl = []\n",
    "i = 0\n",
    "numim = len([x[0] for x in os.walk(src)])\n",
    "for root, directories, filenames in os.walk(src):\n",
    "    start = time.time()\n",
    "    #print(directories)\n",
    "    if ds == []:\n",
    "        ds = directories\n",
    "    for filename in filenames:  \n",
    "        fp = os.path.join(root,filename)\n",
    "        if filename[-5:] == '0.tif':\n",
    "            ci = os.path.join(root,filename)\n",
    "            #print(ci)\n",
    "# #             sg = 3.5\n",
    "#             ii = 0\n",
    "# #             #ni = preproc(ci,printg)\n",
    "#             #tf = 5\n",
    "#             sg = 4\n",
    "#             while ii < 1e6: \n",
    "#                 #tf += 10\n",
    "#                 ni = preproc(ci,sg)\n",
    "#                 ii = np.sum(depth - ni)\n",
    "#                 sg += 1\n",
    "            #print(sg)\n",
    "            #print(np.sum(depth - ni))\n",
    "            #ni = preproc(ci)\n",
    "            ni = preproc(ci)\n",
    "            ci = ci.replace('/598_','/598prc_')\n",
    "            PIL.Image.fromarray(ni).save(ci[:-4]+'prc.tif')\n",
    "            #print('.', end = '')\n",
    "\n",
    "        elif filename[-7:] == '_20.csv':\n",
    "            shutil.copyfile(os.path.join(root,filename),os.path.join(root,filename).replace('/598_','/598prc_'))\n",
    "        fn = time.time()\n",
    "    i+=1\n",
    "    end = time.time()\n",
    "    tl.append(end-start)\n",
    "    #print(tl)\n",
    "    coco(tl,numim)\n",
    "    #print('|', end = '')\n",
    "#PIL.Image.fromarray(ni).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = [0.0, 0.03490328788757324, 0.16156506538391113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[[25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]\n",
      " [25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]\n",
      " [25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]\n",
      " ...\n",
      " [25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]\n",
      " [25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]\n",
      " [25.04971504 25.04971504 25.04971504 ... 25.04971504 25.04971504\n",
      "  25.04971504]]\n"
     ]
    }
   ],
   "source": [
    "#coco(tl, ni)\n",
    "print(ni)\n",
    "print(np.mean(tl)*ni)\n",
    "#print(np.mean(tl)*ni-sum(tl))\n",
    "#ntime(np.mean(tl)*ni-sum(tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:/seva/598prc_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ab59f4641b13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:/seva/598prc_processing'"
     ]
    }
   ],
   "source": [
    "path = dst\n",
    "ds = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtract trapezoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(wt):\n",
    "xshift = int(np.mean([695,685,720,695,700,693,685]))\n",
    "tr = np.zeros([ht,wt])\n",
    "a, b, c = np.mean([173,174,177]), np.mean([92,92,91]), np.mean([310,306,319,308,308,314])\n",
    "h = np.sqrt(c**2-((a-b)/2)**2)\n",
    "for x in range(int(h)-20):\n",
    "    tr[x+xshift,int((a-b)/c/2*(h-x))+yshift:int(x*(a-b)/2/h+(a+b)/2)+yshift] = 255\n",
    "tr = depth - tr\n",
    "PIL.Image.fromarray(tr).show()\n",
    "PIL.Image.fromarray(image*tr/depth).show()\n",
    "print(int((a-b)/c/2*(h-y)),int((a-b)/c/2*(h-y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ds)\n",
    "#x = os.walk(rootdir)\n",
    "#[q, w, e] = os.walk(rootdir)\n",
    "# k = 0\n",
    "# for root, directories, filenames in os.walk(rootdir): \n",
    "#     for filename in filenames:  \n",
    "#         if filename[-3:] == 'csv':\n",
    "#             k += 1\n",
    "def getbatch(cds):\n",
    "    data = t.zeros([k, C_in, nh, nw]).to(device)\n",
    "    label = t.zeros([k, D_out]).to(device)\n",
    "    c, dc = [0]*2\n",
    "    for root, directories, filenames in os.walk(cds): \n",
    "        #for directory in directories:\n",
    "        i = 0\n",
    "        lc = 0\n",
    "        for filename in filenames:\n",
    "            ci = os.path.join(root,filename)\n",
    "            if filename[-3:] == 'csv':\n",
    "                #print(ci,lc)\n",
    "                label[lc,:] = t.tensor(np.genfromtxt(ci, delimiter='\\n'))\n",
    "                lc += 1\n",
    "            if filename[-3:] == 'tif':\n",
    "                #print(ci,dc)\n",
    "                data[dc, i, :, :] = transforms.ToTensor()(cv2.imread(ci, 0)).unsqueeze_(0)\n",
    "                dc += i//2\n",
    "                i += 1\n",
    "    data = data/255\n",
    "    #label = label \n",
    "    return(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = getbatch(os.path.join(dst,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-86a3bac8786f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-86a3bac8786f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print(\"%.2f\",% 3.1414)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f\", % 3.1414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-960ce97e3d13>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-960ce97e3d13>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(\"%.2f\", %(data.element_size() * data.nelement()/1024**3))\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#data = t.zeros([k, 3, 1000, 1800])\n",
    "print(\"%.2f\", %(data.element_size() * data.nelement()/1024**3), 'GB')\n",
    "#print(label.element_size() * label.nelement()/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = t.nn.Linear(nh*nw*C_in, layers[0])\n",
    "        self.linear2 = t.nn.Linear(layers[0],layers[1])\n",
    "        self.linear3 = t.nn.Linear(layers[1],layers[2])\n",
    "        self.linear4 = t.nn.Linear(layers[2], D_out)\n",
    "        self.do = t.nn.Dropout(p=dop)\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        #print('x flattened', x.shape)\n",
    "        #print(nh,nw,C_in, layers[0])\n",
    "        x = self.do(F.leaky_relu(self.linear1(x).clamp(min=0)))\n",
    "        #print(x.shape)\n",
    "        x = self.do(F.leaky_relu(self.linear2(x)))\n",
    "        x = self.do(F.relu(self.linear3(x)))\n",
    "        x = self.do(self.linear4(x))\n",
    "        return x\n",
    "class CNet(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#        super(CNet, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(C_in, 6, 5)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear0 = t.nn.Linear(16*47*47, 1000)\n",
    "        self.linear1 = t.nn.Linear(1000, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv0(x)))\n",
    "        print(x.shape)\n",
    "        #print(t.mean(x))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, x.size(1)*x.size(2)*x.size(3))\n",
    "        x = F.relu(self.linear0(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        #x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnarchitectures = { 'DNet' : DNet, \n",
    "                    'CNet' : CNet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........0:0:0,"
     ]
    }
   ],
   "source": [
    "lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multit():\n",
    "    starta = time.time()\n",
    "#     model = None\n",
    "#     if model is None:\n",
    "    model = nnarchitectures[modelname]()\n",
    "    model.to(device)\n",
    "    optimizer = t.optim.Adam(model.parameters(), lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    tl = []\n",
    "    lossa = np.zeros([2, epochs])\n",
    "    #xval = np.zeros([])\n",
    "    xval = t.zeros([k, C_in, nh, nw]).to(device)\n",
    "    yval = t.zeros([k, D_out]).to(device)\n",
    "    [xval, yval] = getbatch(ds[1])\n",
    "    for j in range(epochs):\n",
    "        start = time.time()  \n",
    "        for i in range(bn):\n",
    "            #print('.', end = '')\n",
    "            #data = idata[i]\n",
    "            [xtrain, ytrain] = getbatch(ds[i+1])\n",
    "            loss = []\n",
    "            criterion = t.nn.MSELoss(reduction='mean')\n",
    "            #start = time.time()\n",
    "            #print(tm)\n",
    "            xtrain = xtrain.detach() #xtrain contains images of the circle\n",
    "            y_pred = model(xtrain) #y_pred consists of coordinates of the circle center and its radius\n",
    "            #print(y_pred.shape)\n",
    "           #print(ytrain.shape)\n",
    "            if ltype == 'supervised': \n",
    "                # Forward pass: Compute predicted y by passing x to the model\n",
    "                #calculating loss between predicted parameters and parameters which were used for generation\n",
    "                loss = criterion(y_pred, ytrain)\n",
    "            else: \n",
    "                #x_pred = t.zeros([N,1,sz,sz])\n",
    "                x_pred = t.zeros([bn,C_in,ht,wt])\n",
    "                for i in range(bn):\n",
    "                    # Generating circles with inferred parameters y_pred.\n",
    "                    #print(y_pred)\n",
    "                    x_pred[i,0,:,:] = ellipses(y_pred, k, sz, device)\n",
    "                # Compute and print loss\n",
    "                # Compare generated image with the input image, finding per-pixel distance between two images\n",
    "                loss = criterion(x_pred, xtrain)\n",
    "                #print(loss.item())\n",
    "            #print('trainig loss counter', i+j*bn)\n",
    "            #lossa[0][i+j*bn] = loss.item() #the first number in the loss is a training loss\n",
    "            #updating list with losses \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #lossc = lossa\n",
    "            #lossa[1][i+j*bn] = criterion(model(xval), yval).item() #the second number in the loss is a validation loss\n",
    "            #print(i+j*bn)\n",
    "#             end = time.time()\n",
    "#             tl.append(end-start)\n",
    "#             ntime(sum(tl) / len(tl)*bn - sum(tl))\n",
    "        lossa[0][j] = loss.item()\n",
    "        lossa[1][j] = criterion(model(xval), yval).item()\n",
    "        end = time.time()\n",
    "        tl.append(end-start)\n",
    "        coco(tl, i+j, epochs)\n",
    "#         l = ntime(sum(tl)/len(tl)*epochs-sum(tl))\n",
    "#         if j%10 != 9:\n",
    "#             print (\"%d:%d:%d,\" % tuple(l), end = '')\n",
    "#         else:\n",
    "#             print (\"%d:%d:%d\" % tuple(l), end = '\\n')\n",
    "    enda = time.time()\n",
    "    timelapse = enda - starta\n",
    "    return(lossa, timelapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:1:28,0:1:4,0:0:48,0:0:36,0:0:27,0:0:20,0:0:14,0:0:9,0:0:4,0:0:0\n"
     ]
    }
   ],
   "source": [
    "lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8, 20)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l[0], l[1], l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:8:20,"
     ]
    }
   ],
   "source": [
    "l = ntime(500)\n",
    "print (\"%d:%d:%d,\" % tuple(l), end = '')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a plot of the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traplot():\n",
    "    plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "    #linestyles = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--', '-.', ':']\n",
    "    colors = ['red', 'green']\n",
    "    axes = plt.gca()\n",
    "    #axes.set_ylim([0,0.02])\n",
    "    labels_text = ['training', 'validation']\n",
    "    #print(lossl.shape)\n",
    "    #print(np.arange(epochs*bn).shape)\n",
    "    for trt in range(len(labels_text)):\n",
    "        plt.plot(np.arange(lossa.shape[1]), lossa[trt][:], label=labels_text[trt], \\\n",
    "                 color = colors[trt], linewidth=3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0., fontsize = 24)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.autoscale(enable=True, axis='both', tight=None)\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('MSE Loss', fontsize=24)\n",
    "    #+n+bn+bs+epochs+lr+imgsize+layers+dop+\n",
    "    plt.savefig('k'+str(k)+'_'+'n'+str(n)+'_'+'_'+'bn'+str(bn)+','+'bs'+str(bs)+'_'+\\\n",
    "                'epochs'+str(epochs)+'_'+'layers'+str(layers)+'_'+'lr'+str(lr)+'_'+'etime'+\\\n",
    "                format(timelapse,\".2f\") + '_' + 'noisein' + str(randinit) +'.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/data/599prc\n"
     ]
    }
   ],
   "source": [
    "print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 #how many epochs \n",
    "lr = 5e-5 #learning rate\n",
    "bn = 1 #how many batches\n",
    "bs = 3 #how many images in a batch\n",
    "layers = [100, 50, 441] #number of neurons at every layer\n",
    "dop = 0 #drop out percentage 0 to 1. \n",
    "randinit = 0 #0 is ellipse generator, 1 is noise generator\n",
    "modelname = 'DNet'\n",
    "ltype = 'supervised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 500, 900])\n",
      "torch.Size([3, 1350000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1350000) must match the size of tensor b (441) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-00076042e8ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlossa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimelapse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-462220632117>\u001b[0m in \u001b[0;36mmultit\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[1;31m# Forward pass: Compute predicted y by passing x to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;31m#calculating loss between predicted parameters and parameters which were used for generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;31m#x_pred = t.zeros([N,1,sz,sz])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dprogramms\\anaconda\\envs\\shreg\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dprogramms\\anaconda\\envs\\shreg\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dprogramms\\anaconda\\envs\\shreg\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dprogramms\\anaconda\\envs\\shreg\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1350000) must match the size of tensor b (441) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "nrows, ncols =1,4\n",
    "fig = plt.figure()\n",
    "for i in range(nrows*ncols):\n",
    "        ax = fig.add_subplot(int(str(nrows)+str(ncols)+str(i+1)), projection='3d') \n",
    "        ax.voxels(datac[i+3][0])\n",
    "        plt.axis('off')\n",
    "        plt.autoscale(enable=True, axis='both', tight=None)\n",
    "#dt = str(datetime.fromtimestamp(int(time.time())))\n",
    "plt.savefig(os.getcwd() + '\\plot output'+'\\k'+str(k)+'_'+'n'+str(n)+'_' +\\\n",
    "            'time' + time.strftime(\"%H%M%S\") + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
