{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform, data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch as t\n",
    "plt.ion()   # interactive mode\n",
    "from skimage.measure import regionprops\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = r'D:\\data\\seeds\\597'.replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/data/seeds/597\n",
      "D:/data/seeds/597\\1234567\n",
      "D:/data/seeds/597\\1234567\\1491988\n",
      "D:/data/seeds/597\\1234567\\1491989\n",
      "D:/data/seeds/597\\1234567\\1491990\n",
      "D:/data/seeds/597\\1234568\n",
      "D:/data/seeds/597\\1234568\\1491991\n",
      "D:/data/seeds/597\\1234568\\1491992\n",
      "D:/data/seeds/597\\1234568\\1491993\n",
      "D:/data/seeds/597\\1234569\n",
      "D:/data/seeds/597\\1234569\\1491994\n",
      "D:/data/seeds/597\\1234569\\1491995\n",
      "D:/data/seeds/597\\1234569\\1491996\n"
     ]
    }
   ],
   "source": [
    "for root, directories, files in os.walk(mainpath):\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, dc = [0]*2\n",
    "tip = []\n",
    "cip = []\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    i = 0\n",
    "    lc = 0\n",
    "    for filename in filenames:\n",
    "        if filename[-5:] == '0.csv':\n",
    "            cip.append(os.path.join(root,filename))\n",
    "        if filename[-3:] == 'tif':\n",
    "            tip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "nip = []\n",
    "for i in range(len(cip)):\n",
    "    nip.append(cip[i][-24:-9])\n",
    "nip = [cip[i][-24:-9] for i in range(len(cip))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1234567\\\\1491988', '1234567\\\\1491989', '1234567\\\\1491990', '1234568\\\\1491991', '1234568\\\\1491992', '1234568\\\\1491993', '1234569\\\\1491994', '1234569\\\\1491995', '1234569\\\\1491996']\n"
     ]
    }
   ],
   "source": [
    "print(nip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_out = 441\n",
    "labels = np.zeros([len(cip),D_out])\n",
    "for i in range(len(cip)):\n",
    "    labels[i,:] = t.tensor(np.genfromtxt(cip[i], delimiter='\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 441)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.rand(441, 3),\n",
    "                   columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            a         b         c\n",
      "0    0.159184  0.508600  0.333547\n",
      "1    0.734241  0.812859  0.901637\n",
      "2    0.405015  0.381278  0.869288\n",
      "3    0.912624  0.573823  0.647296\n",
      "4    0.141828  0.812526  0.275240\n",
      "..        ...       ...       ...\n",
      "436  0.122091  0.459071  0.435498\n",
      "437  0.225559  0.939717  0.380885\n",
      "438  0.321445  0.803476  0.377327\n",
      "439  0.408589  0.780000  0.419866\n",
      "440  0.317190  0.253357  0.442873\n",
      "\n",
      "[441 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frange(0, 441)'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'f'+str(range(D_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen = []\n",
    "for i in range(D_out):\n",
    "    fen.append('f'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(data=labels,index=range(len(cip)),columns=fen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.insert(0, 'file_name', nip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         file_name          f0        f1        f2        f3        f4  \\\n",
      "0  1234567\\1491988  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "1  1234567\\1491989  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "2  1234567\\1491990  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "3  1234568\\1491991  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "4  1234568\\1491992  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "5  1234568\\1491993  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "6  1234569\\1491994  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "7  1234569\\1491995  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "8  1234569\\1491996  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "\n",
      "         f5         f6        f7        f8  ...      f431      f432      f433  \\\n",
      "0  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "1  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "2 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "3  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "4  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "5 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "6  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "7  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "8 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "\n",
      "       f434      f435      f436      f437      f438      f439      f440  \n",
      "0 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "1 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "2  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "3 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "4 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "5  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "6 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "7 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "8  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "\n",
      "[9 rows x 442 columns]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/data/seeds/597\n"
     ]
    }
   ],
   "source": [
    "print(mainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv(mainpath+'/sh_paramters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         file_name          f0        f1        f2        f3        f4  \\\n",
      "0  1234567\\1491988  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "1  1234567\\1491989  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "2  1234567\\1491990  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "3  1234568\\1491991  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "4  1234568\\1491992  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "5  1234568\\1491993  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "6  1234569\\1491994  116.405220 -4.513279 -1.220708  2.530450  1.256154   \n",
      "7  1234569\\1491995  113.802608 -1.821341 -4.094612 -4.358083  0.090340   \n",
      "8  1234569\\1491996  103.478474  2.322272 -1.303382 -3.381546 -0.709873   \n",
      "\n",
      "         f5         f6        f7        f8  ...      f431      f432      f433  \\\n",
      "0  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "1  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "2 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "3  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "4  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "5 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "6  1.597190  28.478109 -0.338765 -4.024844  ... -0.019068  0.018543  0.012647   \n",
      "7  0.940660  28.885142  0.451164 -3.762432  ...  0.032601 -0.007680 -0.002492   \n",
      "8 -1.580764  26.299449  1.166809 -7.417066  ...  0.220268  0.047728 -0.117930   \n",
      "\n",
      "       f434      f435      f436      f437      f438      f439      f440  \n",
      "0 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "1 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "2  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "3 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "4 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "5  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "6 -0.141428 -0.029373  0.027103 -0.002351  0.024784 -0.043243 -0.085931  \n",
      "7 -0.039333  0.105820  0.079150  0.004004 -0.027402 -0.013012  0.010330  \n",
      "8  0.032957 -0.019080  0.013763 -0.003878 -0.024684  0.026475 -0.002818  \n",
      "\n",
      "[9 rows x 442 columns]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16405220e+02 -4.51327859e+00 -1.22070813e+00 ...  2.47839955e-02\n",
      "  -4.32429744e-02 -8.59312268e-02]\n",
      " [ 1.13802608e+02 -1.82134061e+00 -4.09461169e+00 ... -2.74015844e-02\n",
      "  -1.30121494e-02  1.03304322e-02]\n",
      " [ 1.03478474e+02  2.32227230e+00 -1.30338161e+00 ... -2.46842329e-02\n",
      "   2.64750406e-02 -2.81838652e-03]\n",
      " ...\n",
      " [ 1.16405220e+02 -4.51327859e+00 -1.22070813e+00 ...  2.47839955e-02\n",
      "  -4.32429744e-02 -8.59312268e-02]\n",
      " [ 1.13802608e+02 -1.82134061e+00 -4.09461169e+00 ... -2.74015844e-02\n",
      "  -1.30121494e-02  1.03304322e-02]\n",
      " [ 1.03478474e+02  2.32227230e+00 -1.30338161e+00 ... -2.46842329e-02\n",
      "   2.64750406e-02 -2.81838652e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name: 1234569\\1491995\n",
      "Landmarks shape: (1, 441)\n"
     ]
    }
   ],
   "source": [
    "#landmarks_frame = pd.read_csv('D:/data/faces/face_landmarks.csv')\n",
    "landmarks_frame = pd.read_csv(mainpath+ '/sh_paramters.csv')\n",
    "n = 7\n",
    "img_name = landmarks_frame.iloc[n, 0]\n",
    "landmarks = landmarks_frame.iloc[n, 1:]\n",
    "landmarks = np.asarray(landmarks)\n",
    "landmarks = landmarks.astype('float').reshape(-1, D_out)\n",
    "\n",
    "print('Image name: {}'.format(img_name))\n",
    "print('Landmarks shape: {}'.format(landmarks.shape))\n",
    "#print('First 4 Landmarks: {}'.format(landmarks[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_landmarks(image, landmarks):\n",
    "#     \"\"\"Show image with landmarks\"\"\"\n",
    "#     plt.imshow(image)\n",
    "#     plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# plt.figure()\n",
    "# show_landmarks(io.imread(os.path.join('D:/data/faces/', img_name)),\n",
    "#                landmarks)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #print(self.landmarks_frame.iloc[idx, 0])\n",
    "#         img_name = os.path.join(self.root_dir,\n",
    "#                                 self.landmarks_frame.iloc[idx, 0],'/rotation_000prc.tif')\n",
    "        img = np.zeros([3,1000,1800,1])\n",
    "        for i in range(3):\n",
    "            #print(str(120*i).zfill(3))\n",
    "            img_name = self.root_dir+'/'+self.landmarks_frame.iloc[idx, 0]+\\\n",
    "            '/rotation_'+ str(120*i).zfill(3) + '.tif'\n",
    "#        imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "            img[i] = np.expand_dims(np.asarray(io.imread(img_name)), axis=2)\n",
    "        #print(img.shape)\n",
    "        #print(img_name)\n",
    "        #image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, D_out)\n",
    "        sample = {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(3, 1000, 1800, 1) (1, 441)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oldf = 'D:/data/faces/face_landmarks.csv'\n",
    "face_dataset = FaceLandmarksDataset(csv_file=mainpath+'/sh_paramters.csv',\n",
    "                                    root_dir=mainpath)\n",
    "print(len(face_dataset))\n",
    "fig = plt.figure()\n",
    "sample = face_dataset[0]\n",
    "print(sample['image'].shape, sample['landmarks'].shape)\n",
    "\n",
    "# for i in range(len(face_dataset)):\n",
    "#     sample = face_dataset[i]\n",
    "\n",
    "#     print(i, sample['image'].shape, sample['landmarks'].shape)\n",
    "\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "# #    show_landmarks(**sample)\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = []\n",
    "for root, directories, filenames in os.walk(mainpath): \n",
    "    for filename in filenames:\n",
    "        if filename[-5:] == '0.csv':\n",
    "            cip.append(os.path.join(root,filename))\n",
    "len(cip)\n",
    "labels = np.zeros([len(cip),D_out])\n",
    "for i in range(len(cip)):\n",
    "    labels[i,:] = t.tensor(np.genfromtxt(cip[i], delimiter='\\n'))\n",
    "lmean = np.mean(labels, axis = 0)\n",
    "lstd = np.std(labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Normalize(lmean, lstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalize(mean=(0.4915, 0.4823, 0.4468), std=(0.247, 0.2435, 0.2616))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(\\\n",
    "data_path, train=True, download=False,transform=transforms.Compose([\\\n",
    "transforms.ToTensor(),\\\n",
    "transforms.Normalize((0.4915, 0.4823, 0.4468),\\\n",
    "(0.2470, 0.2435, 0.2616))\\\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "t = (1,2)\n",
    "print(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Norm(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, tmean):\n",
    "        assert isinstance(tmean, tuple)\n",
    "        self.tmean = tmean\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        landmarks = (landmarks - self.tmean[0])/self.tmean[1]\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "#        image = image.transpose((0,1,1))\n",
    "#        print(image.shape)\n",
    "#        print('.', end='')\n",
    "        return {'image': image,\n",
    "                'landmarks': landmarks}\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "#        image = image.transpose((0,1,1))\n",
    "#        print(image.shape)\n",
    "#        print('.', end='')\n",
    "        landmarks = np.squeeze(landmarks)\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "class CmsCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image[0].shape[0:2]\n",
    "        #print(image[0].shape)\n",
    "        #print(h, w)\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "                #print(new_h, new_w)\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "#     def __init__(self, output_size):\n",
    "#         assert isinstance(output_size, (int, tuple))\n",
    "#         if isinstance(output_size, int):\n",
    "#             self.output_size = (output_size, output_size)\n",
    "#         else:\n",
    "#             assert len(output_size) == 2\n",
    "#             self.output_size = output_size\n",
    "\n",
    "#     def __call__(self, sample):\n",
    "#         image, landmarks = sample['image'], sample['landmarks']\n",
    "#        h, w = image.shape[1:3]\n",
    "        h, w = image[0].shape[0:2]\n",
    "        #print(image[0].shape)\n",
    "#        new_h, new_w = self.output_size\n",
    "        #print(new_w)\n",
    "        new_image = np.zeros([3,new_h, new_w])\n",
    "        for i in range(3):\n",
    "            img = np.squeeze(255-image[i])\n",
    "            #nimage = fmask*image\n",
    "        #     qmask = ndi.binary_fill_holes(canny(timage/depth,sigma=sg)+frame)\n",
    "        #     nimage = (1-frame)*qmask*image\n",
    "#             print(filters.threshold_otsu(img))\n",
    "#             print((img > filters.threshold_otsu(img)).shape)\n",
    "            properties = regionprops((img > filters.threshold_otsu(img)).astype(int), img)\n",
    "            cms = tuple(map(lambda x: int(x), properties[0].centroid))\n",
    "            new_image[i] = (255-img[cms[0]-new_h//2:cms[0]+new_h//2,\\\n",
    "                                  cms[1]-new_w//2:cms[1]+new_w//2]).astype(np.uint8)\n",
    "#         top = np.random.randint(0, h - new_h)\n",
    "#         left = np.random.randint(0, w - new_w)\n",
    "\n",
    "#         image = image[top: top + new_h,\n",
    "#                       left: left + new_w]\n",
    "\n",
    "#         landmarks = landmarks - [left, top]\n",
    "#        print('_', end='')\n",
    "        return {'image': new_image, 'landmarks': landmarks}\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image[0].shape[0:2]\n",
    "#        print(image[0].shape)\n",
    "#        h, w = image[0].shape[1:3]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = np.zeros([3,new_h, new_w])\n",
    "        for i in range(3):\n",
    "            img[i] = transform.resize(img[i], (new_h, new_w))\n",
    "        transforms.ToTensor()\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    " #       landmarks = landmarks * [new_w / w, new_h / h]\n",
    "        print('.', end='')\n",
    "        return {'image': img, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "# scale = Rescale(300)\n",
    "# crop = CmsCrop(500)\n",
    "# totensor = ToTensor()\n",
    "composed = transforms.Compose([CmsCrop(500),Rescale(300),Norm((lmean, lstd)),ToTensor()])\n",
    "# Apply each of the above transforms on sample.\n",
    "#fig = plt.figure()\n",
    "# for j in range(len(face_dataset)):\n",
    "#     sample = face_dataset[j]\n",
    "#     #print(sample['image'][0].shape[:2])\n",
    "#     #transformed_sample = t.zeros([3,1,1000,1800])\n",
    "#     for i, tsfrm in enumerate([totensor, crop, scale,composed]):\n",
    "#         #for j in range(3):\n",
    "#sample = face_dataset[0]\n",
    "transformed_sample = composed(face_dataset[0])\n",
    "#     ax = plt.subplot(1, 3, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title(type(tsfrm).__name__)\n",
    "#     show_landmarks(**transformed_sample)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 300, 540])\n"
     ]
    }
   ],
   "source": [
    "print(transformed_sample['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(face_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/data/seeds/597\n"
     ]
    }
   ],
   "source": [
    "print(mainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 990)\n",
      ".(550, 990)\n",
      ".(550, 990)\n",
      ".(550, 990)\n",
      "."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    #print(i, sample['image'].size(), sample['landmarks'].size())\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....0 torch.Size([4, 3, 550, 990]) torch.Size([4, 441])\n",
      "....1 torch.Size([4, 3, 550, 990]) torch.Size([4, 441])\n",
      ".2 torch.Size([1, 3, 550, 990]) torch.Size([1, 441])\n"
     ]
    }
   ],
   "source": [
    "transformed_dataset = FaceLandmarksDataset(csv_file=mainpath+'/sh_paramters.csv',\n",
    "                                           root_dir=mainpath,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               CmsCrop(550),\n",
    "                                               Rescale(550),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "# Helper function to show a batch\n",
    "def show_landmarks_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = \\\n",
    "            sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "#    grid_border_size = 2\n",
    "\n",
    "#    grid = utils.make_grid(images_batch)\n",
    "#    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        print(i)\n",
    "#         plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,\n",
    "#                     landmarks_batch[i, :, 1].numpy() + grid_border_size,\n",
    "#                     s=10, marker='.', c='r')\n",
    "\n",
    "#         plt.title('Batch from dataloader')\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    #torch.utils.data.TensorDataset(*tensors: torch.Tensor)\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['landmarks'].size())\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "#         plt.figure()\n",
    "#         show_landmarks_batch(sample_batched)\n",
    "#         plt.axis('off')\n",
    "#         plt.ioff()\n",
    "#         plt.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataloader, 'D:/data/seeds/dataloader.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
