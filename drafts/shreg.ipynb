{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import imageio as iio\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray  # only needed for incorrectly saved images\n",
    "from skimage.measure import regionprops\n",
    "from skimage.feature import canny\n",
    "from scipy import ndimage as ndi\n",
    "import shutil\n",
    "#from models.res_gru_net import ResidualGRUNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 2**8-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters depended on dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src = r'D:\\data\\599'.replace('\\\\', '/')\n",
    "src = r'D:\\seva\\598_processing'.replace('\\\\', '/')\n",
    "ido = '598'\n",
    "idn = ido + 'prc'\n",
    "dst = src.replace(ido,idn)\n",
    "k = 120 #how many csv files in a folder, maximum is 120\n",
    "C_in = 3 #how many views of one seed\n",
    "D_out = 441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (if t.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timelapse printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ntime(s):\n",
    "    m = 60\n",
    "    l = [(s/m**2)%24, (s/m)%m, (s)%m]\n",
    "    return([int(x) for x in l])\n",
    "def coco(tl, ni, pt):\n",
    "    sm = sum(tl)\n",
    "    tt = 10*(pt)\n",
    "    if sm > tt: \n",
    "        l = tuple(ntime(np.mean(tl)*ni-sum(tl)))\n",
    "    else: \n",
    "        return([pt,'',''])\n",
    "    if sm > tt and pt%15 != 14:\n",
    "        return([pt+1,str(\"%02d:%02d:%02d,\" % l),''])\n",
    "    elif sm > tt and pt%15 == 14:\n",
    "        return([pt+1,str(\"%02d:%02d:%02d,\" % l),'\\n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, dc = [0]*2\n",
    "tip = []\n",
    "cip = []\n",
    "for root, directories, filenames in os.walk(r'D:\\seva\\598prc_processing'.replace('\\\\', '/')): \n",
    "    i = 0\n",
    "    lc = 0\n",
    "    for filename in filenames:\n",
    "        if filename[-3:] == 'csv':\n",
    "            cip.append(os.path.join(root,filename))\n",
    "        if filename[-3:] == 'tif':\n",
    "            tip.append(os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 90, 50\n",
    "imp = r'D:\\seva\\598prc_processing\\1484717\\1491988\\rotation_000prc.tif'.replace('\\\\', '/')\n",
    "im = PIL.Image.open(imp).resize(size, PIL.Image.ANTIALIAS)\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "bcr = 0\n",
    "D_out = 441\n",
    "C_in = 3\n",
    "def getbatch(bcr):\n",
    "    label = t.zeros([bs, D_out]).to(device)\n",
    "    for i in range(bs):\n",
    "        label[i,:] = labelsb[i+bcr*bs,:].to(device)\n",
    "    if randinit:\n",
    "        data = t.rand([bs, C_in, nh, nw]).to(device)\n",
    "    else:\n",
    "        data = t.zeros([bs, C_in, nh, nw]).to(device)\n",
    "        for i in range(bs):\n",
    "            for j in range(C_in):\n",
    "                data[i,j,:,:] = transforms.ToTensor()(\\\n",
    "                                PIL.Image.open(tip[C_in*i+j])\\\n",
    "                                .resize([nw,nh], PIL.Image.ANTIALIAS)).unsqueeze_(0)  \n",
    "    return(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros([len(cip),D_out])\n",
    "for i in range(len(cip)):\n",
    "    labels[i,:] = t.tensor(np.genfromtxt(cip[i], delimiter='\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsb = t.tensor((labels - np.mean(labels, axis = 0))/np.std(labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howbig(ten):\n",
    "    print(\"%.2f\" % (ten.element_size() * ten.nelement()/1024**3), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howbig(labelsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsize(szi,ker,srd): \n",
    "    pad = (0,0)\n",
    "    dil = np.asarray((0,0))\n",
    "    return(tuple((np.squeeze((szi+2*np.asarray(pad)-dil*[np.asarray(ker)-1]+1)/np.asarray(srd))).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 32\n",
    "def szo(sz,ker,srd,pad):\n",
    "    sz = int(np.floor((sz+2*pad-ker)/srd))+1\n",
    "    #print(sz)\n",
    "    return(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = szo(sz,5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = t.nn.Linear(nh*nw*C_in, layers[0])\n",
    "        self.linear2 = t.nn.Linear(layers[0],layers[1])\n",
    "        self.linear3 = t.nn.Linear(layers[1],layers[2])\n",
    "        self.linear4 = t.nn.Linear(layers[2],layers[3])\n",
    "        self.linear5 = t.nn.Linear(layers[3],layers[4])\n",
    "        self.do = t.nn.Dropout(p=dop)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.do(F.leaky_relu(self.linear1(x).clamp(min=0)))\n",
    "        x = self.do(F.leaky_relu(self.linear2(x)))\n",
    "        x = self.do(F.leaky_relu(self.linear3(x)))\n",
    "        x = self.do(F.leaky_relu(self.linear4(x)))\n",
    "        x = self.do(self.linear5(x))\n",
    "        return x\n",
    "class CNet(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(C_in, 8, (5,5))\n",
    "        self.conv1 = nn.Conv2d(8, 16, (5,5))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        sz = getsize((nh,nw),(5,5),(1,1))\n",
    "        sz = getsize(sz,(2,2),(2,2))\n",
    "        sz = getsize(sz,(5,5),(1,1))\n",
    "        sz = getsize(sz,2,2)\n",
    "        sz = np.asarray(sz)-4-int((sc/2)%2)\n",
    "        self.linear0 = t.nn.Linear(16*sz[0]*sz[1], 1000)\n",
    "        self.linear1 = t.nn.Linear(1000, D_out)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv0(x)))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.linear0(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return x\n",
    "nnarchitectures = { 'DNet' : DNet, \n",
    "                    'CNet' : CNet}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multit():\n",
    "#     print('size='+str(nh)+'x'+str(nw)+\\\n",
    "#           ', bn='+str(bn)+\\\n",
    "#             ', bs='+str(bs)+\\\n",
    "#             ', epochs='+str(epochs)+\\\n",
    "#             ', layers='+str(layers)+\\\n",
    "#             ', lr='+str(lr)+\\\n",
    "#             ', noisein='+str(randinit)) \n",
    "    starta = time.time()\n",
    "    #model = None\n",
    "#   if model is None:\n",
    "    model = nnarchitectures[modelname]()\n",
    "    model.to(device)\n",
    "    optimizer = t.optim.Adam(model.parameters(), lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    tl = []\n",
    "    pt = 0\n",
    "    lossa = np.zeros([2, epochs])\n",
    "    xval, xtest = [t.zeros([bs, C_in, nh, nw]).to(device)]*2\n",
    "    yval, ytest = [t.zeros([bs, D_out]).to(device)]*2\n",
    "    [xtest, ytest] = getbatch(0)\n",
    "    [xval, yval] = getbatch(1)\n",
    "    for j in range(epochs):\n",
    "        start = time.time()  \n",
    "        for i in range(bn):\n",
    "            [xtrain, ytrain] = getbatch(i+2)\n",
    "            try:\n",
    "                del loss\n",
    "            except:\n",
    "                1\n",
    "            criterion = t.nn.MSELoss(reduction='mean')\n",
    "            xtrain = xtrain.detach() #xtrain contains images of the circle\n",
    "            y_pred = model(xtrain) #y_pred consists of coordinates of the circle center and its radius\n",
    "            if ltype == 'supervised': \n",
    "                # Forward pass: Compute predicted y by passing x to the model\n",
    "                #calculating loss between predicted parameters and parameters which were used for generation\n",
    "                loss = criterion(y_pred, ytrain)\n",
    "            else: \n",
    "                x_pred = t.zeros([bn,C_in,ht,wt])\n",
    "                for i in range(bn):\n",
    "                    # Generating circles with inferred parameters y_pred.\n",
    "                    x_pred[i,0,:,:] = ellipses(y_pred, k, sz, device)\n",
    "                # Compute and print loss\n",
    "                # Compare generated image with the input image, finding per-pixel distance between two images\n",
    "                loss = criterion(x_pred, xtrain)\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        lossa[0][j] = loss.item()\n",
    "        lossa[1][j] = criterion(model(xval), yval).item()\n",
    "        del loss\n",
    "        end = time.time()\n",
    "        tl.append(end-start)\n",
    "        col = coco(tl,epochs, pt)\n",
    "        pt = col[0]\n",
    "        print(col[1], end = col[2])\n",
    "    enda = time.time()\n",
    "    timelapse = enda - starta\n",
    "    return(model, lossa, timelapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a plot of the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traplot():\n",
    "    ymin, ymax = -4, -2\n",
    "    plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "    linestyles = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--', '-.', ':']\n",
    "    colors = ['red', 'green']\n",
    "    axes = plt.gca()\n",
    "    labels_text = [['train', 'validation'], ['train rand input', 'validation rand input']]\n",
    "    axes.set_ylim([ymin,ymax])\n",
    "    for trt in range(2):\n",
    "        for isr in range(2):\n",
    "            plt.plot(np.arange(lossb.shape[2]), \\\n",
    "                     np.log(lossb[isr][trt][:]), label=labels_text[trt][isr], \\\n",
    "                     color = colors[isr], linestyle=linestyles[trt], linewidth=3)\n",
    "    axes.set_xticks(np.arange(0, int(lossb[0][0].shape[0]*1.1),\\\n",
    "                              int(lossb[0][0].shape[0]*0.1)))\n",
    "    #axes.set_yticks(np.arange(ymin, ymax, 1))\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0., fontsize = 24)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    #plt.autoscale(enable=True, axis='both', tight=None)\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('log(MSE Loss)', fontsize=24)\n",
    "    plt.savefig('size='+str([nh, nw])+\\\n",
    "            'bn'+str(bn)+\\\n",
    "            'bs'+str(bs)+\\\n",
    "            'epochs'+str(epochs)+\\\n",
    "            'layers'+str(layers)+\\\n",
    "            'lr'+str(lr)+\\\n",
    "            'etime'+format(timelapse,\".2f\")+\\\n",
    "            'noisein'+str(randinit)+\\\n",
    "                '.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 #how many epochs \n",
    "lr = 5e-5 #learning rate\n",
    "bn = 1 #how many batches\n",
    "bs = 1 #how many images in a batch\n",
    "layers = [4096, 2048, 1024, 750, D_out] #number of neurons at every layer\n",
    "#layers = [650, 600, D_out] #number of neurons at every layer\n",
    "#layers = [D_out] #number of neurons at every layer\n",
    "dop = 0 #drop out percentage 0 to 1. \n",
    "#randinit = 1 #0 is ellipse generator, 1 is noise generator\n",
    "modelname = 'CNet'\n",
    "ltype = 'supervised'\n",
    "lossb = np.zeros([2, 2, epochs])\n",
    "# nh, nw = [5, 9]*10\n",
    "# sk = 9\n",
    "# sc = 4*sk+2\n",
    "sc = 100\n",
    "nh = 5*sc\n",
    "nw = 9*sc\n",
    "t.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randinit = 0\n",
    "#model = None\n",
    "t.cuda.empty_cache()\n",
    "_, lossb[0,:,:], timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sk in range(0,10,1):\n",
    "#     sc = 4*sk+3\n",
    "#     try:\n",
    "#         model, lossb[0,:,:], timelapse = multit(sc)\n",
    "#     except:\n",
    "#         print(sk, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     try:\n",
    "#         x = int(input(\"Please enter a number: \"))\n",
    "#         break\n",
    "#     except ValueError:\n",
    "#         print(\"Oops!  That was no valid number.  Try again...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs in range(50,100,10):\n",
    "    t.cuda.empty_cache()\n",
    "    randinit = 0\n",
    "    model, lossb[0,:,:], timelapse = multit()\n",
    "    del model\n",
    "    t.cuda.empty_cache()\n",
    "    randinit = 1\n",
    "    model, lossb[1,:,:], timelapse = multit()\n",
    "    traplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lossa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randinit = 0\n",
    "model, lossb[0,:,:], timelapse = multit()\n",
    "randinit = 1\n",
    "model, lossb[1,:,:], timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 #how many epochs \n",
    "lr = 5e-5 #learning rate\n",
    "bn = 10 #how many batches\n",
    "bs = 1 #how many images in a batch\n",
    "#layers = [4096, 2048, 1024, 750, 441] #number of neurons at every layer\n",
    "#layers = [650, 600, D_out] #number of neurons at every layer\n",
    "layers = [D_out] #number of neurons at every layer\n",
    "dop = 0 #drop out percentage 0 to 1. \n",
    "randinit = 1 #0 is ellipse generator, 1 is noise generator\n",
    "modelname = 'DNet'\n",
    "ltype = 'supervised'\n",
    "lossb = np.zeros([2, 2, epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, lossa, timelapse = multit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "nrows, ncols =1,4\n",
    "fig = plt.figure()\n",
    "for i in range(nrows*ncols):\n",
    "        ax = fig.add_subplot(int(str(nrows)+str(ncols)+str(i+1)), projection='3d') \n",
    "        ax.voxels(datac[i+3][0])\n",
    "        plt.axis('off')\n",
    "        plt.autoscale(enable=True, axis='both', tight=None)\n",
    "#dt = str(datetime.fromtimestamp(int(time.time())))\n",
    "plt.savefig(os.getcwd() + '\\plot output'+'\\k'+str(k)+'_'+'n'+str(n)+'_' +\\\n",
    "            'time' + time.strftime(\"%H%M%S\") + '.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
